import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from googleapiclient.discovery import build
from datetime import datetime, timedelta
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from anthropic import Anthropic
import json
import os
from dotenv import load_dotenv
import time  # time ëª¨ë“ˆ ì¶”ê°€
import requests
from datetime import datetime, timedelta, timezone
import pytz
from supabase import create_client

class AuthManager:
    def __init__(self):
        load_dotenv()
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY')  # ì—¬ê¸°ë¥¼ ìˆ˜ì •
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if not self.supabase_url or not self.supabase_key:
            try:
                self.supabase_url = st.secrets["SUPABASE_URL"]
                self.supabase_key = st.secrets["SUPABASE_ANON_KEY"]  # ì—¬ê¸°ë„ ìˆ˜ì •
            except:
                st.error("Supabase ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return
                
        self.supabase = create_client(self.supabase_url, self.supabase_key)
        
    def signup(self, email, password):
        try:
            response = self.supabase.auth.sign_up({
                "email": email,
                "password": password
            })
            return True, "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return False, f"íšŒì›ê°€ì… ì‹¤íŒ¨: {str(e)}"
            
    def login(self, email, password):
        try:
            response = self.supabase.auth.sign_in_with_password({
                "email": email,
                "password": password
            })
            return True, response.user
        except Exception as e:
            return False, f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {str(e)}"
            
    def logout(self):
        try:
            self.supabase.auth.sign_out()
            return True
        except Exception as e:
            return False

class YouTubeAnalytics:
    def __init__(self):
        self.auth = AuthManager()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'logged_in' not in st.session_state:
            st.session_state.logged_in = False
            
        st.set_page_config(page_title="YouTube ì½˜í…ì¸  ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
        
        # ë¡œê·¸ì¸ ìƒíƒœê°€ ì•„ë‹ ë•ŒëŠ” ë¡œê·¸ì¸/íšŒì›ê°€ì… UI í‘œì‹œ
        if not st.session_state.logged_in:
            self.show_auth_ui()
        else:
            # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ
            self.quota_limit = 10000
            self.quota_used = 0
            self.cache = {}
            self.load_api_keys()
            self.setup_sidebar()
            
    def show_auth_ui(self):
        st.title("ğŸ” ë¡œê·¸ì¸")
        
        tab1, tab2 = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"])
        
        with tab1:
            email = st.text_input("ì´ë©”ì¼", key="login_email")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_password")
            
            if st.button("ë¡œê·¸ì¸", use_container_width=True):
                if email and password:
                    success, result = self.auth.login(email, password)
                    if success:
                        st.session_state.logged_in = True
                        st.success("ë¡œê·¸ì¸ ì„±ê³µ!")
                        st.rerun()
                    else:
                        st.error(result)
                else:
                    st.warning("ì´ë©”ì¼ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
        with tab2:
            email = st.text_input("ì´ë©”ì¼", key="signup_email")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="signup_password")
            password_confirm = st.text_input("ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password")
            
            if st.button("íšŒì›ê°€ì…", use_container_width=True):
                if email and password and password_confirm:
                    if password != password_confirm:
                        st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        success, message = self.auth.signup(email, password)
                        if success:
                            st.success(message)
                        else:
                            st.error(message)
                else:
                    st.warning("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def setup_sidebar(self):
        with st.sidebar:
            st.title("âš™ï¸ ê²€ìƒ‰ ì„¤ì •")
            
            # ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼ ì¶”ê°€
            if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout"):
                if self.auth.logout():
                    st.session_state.logged_in = False
                    st.rerun()
            
            # API í‚¤ ì…ë ¥ í•„ë“œ (ì´ë¯¸ ë¡œë“œëœ í‚¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ í‘œì‹œ)
            if not self.youtube_api_key:
                self.youtube_api_key = st.text_input("YouTube API Key", type="password")
            if not self.claude_api_key:
                self.claude_api_key = st.text_input("Claude API Key", type="password")
            
            self.keyword = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œ")
            self.max_results = st.slider("ê²€ìƒ‰í•  ìµœëŒ€ ì˜ìƒ ìˆ˜", 10, 100, 50)
            self.date_range = st.slider("ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 24, 12)
            
    def collect_videos_data(self, youtube):
        cache_key = f"{self.keyword}_{self.date_range}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            return self.cache[cache_key]
            
        try:
            date_limit = (datetime.now() - timedelta(days=30 * self.date_range)).isoformat() + "Z"
            
            # search().list í˜¸ì¶œ ì „ í• ë‹¹ëŸ‰ í™•ì¸ (100 units)
            self.check_quota(100)
            
            # ì²« ë²ˆì§¸ API í˜¸ì¶œ: ê²€ìƒ‰ ë° snippet ì •ë³´ í•¨ê»˜ ê°€ì ¸ì˜¤ê¸°
            search_response = youtube.search().list(
                q=self.keyword,
                type="video",
                part="id,snippet",  # snippet í¬í•¨í•˜ì—¬ API í˜¸ì¶œ ìµœì†Œí™”
                maxResults=min(50, self.max_results),
                publishedAfter=date_limit
            ).execute()
            
            videos = []
            video_ids = []
            
            for item in search_response.get('items', []):
                # publishedAtì„ datetime ê°ì²´ë¡œ íŒŒì‹±í•˜ê³  ëª…ì‹œì ìœ¼ë¡œ UTCë¡œ ì²˜ë¦¬
                published_at = datetime.strptime(
                    item['snippet']['publishedAt'], 
                    '%Y-%m-%dT%H:%M:%SZ'
                ).replace(tzinfo=timezone.utc)
                
                videos.append({
                    'id': item['id']['videoId'],
                    'title': item['snippet']['title'],
                    'publishedAt': published_at.isoformat(),  # ISO í˜•ì‹ìœ¼ë¡œ ì €ì¥
                    'description': item['snippet']['description']
                })
                video_ids.append(item['id']['videoId'])
            
            if video_ids:
                # videos().list í˜¸ì¶œ ì „ í• ë‹¹ëŸ‰ í™•ì¸ (1 unit per video)
                self.check_quota(len(video_ids))
                
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                time.sleep(0.5)
                
                # ë‘ ë²ˆì§¸ API í˜¸ì¶œ: í†µê³„ ì •ë³´
                videos_response = youtube.videos().list(
                    part='statistics,contentDetails',
                    id=','.join(video_ids)
                ).execute()
                
                # videos().list í˜¸ì¶œ í›„ì— ëŒ“ê¸€ ìˆ˜ì§‘ ì¶”ê°€
                for video in videos:
                    try:
                        # ëŒ“ê¸€ ìˆ˜ì§‘ ì „ í• ë‹¹ëŸ‰ í™•ì¸
                        self.check_quota(1)
                        comments_response = youtube.commentThreads().list(
                            part="snippet",
                            videoId=video['id'],
                            maxResults=100
                        ).execute()
                        
                        video['comments_data'] = [
                            item['snippet']['topLevelComment']['snippet']['textDisplay']
                            for item in comments_response.get('items', [])
                        ]
                    except Exception as e:
                        video['comments_data'] = []
                
                for video_data in videos_response.get('items', []):
                    video_id = video_data['id']
                    for video in videos:
                        if video['id'] == video_id:
                            stats = video_data['statistics']
                            video.update({
                                'views': int(stats.get('viewCount', 0)),
                                'likes': int(stats.get('likeCount', 0)),
                                'comments': int(stats.get('commentCount', 0)),
                                'duration': video_data['contentDetails']['duration']
                            })
            
            # 1000íšŒ ì´ìƒ ì¡°íšŒëœ ì˜ìƒ í•„í„°ë§
            filtered_videos = [
                video for video in videos 
                if video.get('views', 0) >= 1000
            ]
            
            processed_videos = self.calculate_engagement_scores(filtered_videos)
            
            # ê²°ê³¼ ìºì‹±
            self.cache[cache_key] = processed_videos
            
            return processed_videos
            
        except Exception as e:
            st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []

    def calculate_engagement_scores(self, videos):
        if not videos:
            return []
            
        # ëŒ“ê¸€ ë¹„ìœ¨ ë¶„ì„ì„ í†µí•œ ì´ìƒì¹˜ ì œê±°
        comment_ratios = [
            (video['comments'] / video['views'] * 100) 
            for video in videos if video['views'] > 0
        ]
        avg_ratio = np.mean(comment_ratios)
        std_ratio = np.std(comment_ratios)
        threshold = avg_ratio + (2 * std_ratio)
        
        one_week_ago = datetime.now() - timedelta(days=7)
        
        processed_videos = []
        for video in videos:
            try:
                views = video['views']
                likes = video['likes']
                comments = video['comments']
                
                # ISO í˜•ì‹ ë‚ ì§œ íŒŒì‹± ìˆ˜ì •
                publish_date = pd.to_datetime(video['publishedAt']).replace(tzinfo=None)
                
                comment_ratio = (comments / views * 100) if views > 0 else 0
                
                # ë¹„ì •ìƒì ì¸ ëŒ“ê¸€ ë¹„ìœ¨ ì œì™¸
                if comment_ratio > threshold:
                    continue
                    
                like_ratio = (likes / views * 100) if views > 0 else 0
                recency_score = 1.2 if publish_date > one_week_ago else 1.0
                
                engagement_score = (
                    like_ratio + 
                    (comment_ratio * 3)  # ëŒ“ê¸€ ê°€ì¤‘ì¹˜ 3ë°°
                ) * recency_score
                
                video['engagement_score'] = engagement_score
                video['like_ratio'] = like_ratio
                video['comment_ratio'] = comment_ratio
                video['is_recent'] = publish_date > one_week_ago
                
                processed_videos.append(video)
                
            except Exception as e:
                st.warning(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ì¸ê²Œì´ì§€ë¨¼íŠ¸ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        return sorted(
            processed_videos, 
            key=lambda x: x['engagement_score'], 
            reverse=True
        )[:20]  # ìƒìœ„ 20ê°œë§Œ ë°˜í™˜
        
    def calculate_weekday_stats(self, df):
        # date ì»¬ëŸ¼ì´ datetime íƒ€ì…ì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜
        df['date'] = pd.to_datetime(df['date'])
        try:
            df['date'] = df['date'].dt.tz_localize(None).tz_localize('UTC').tz_convert('Asia/Seoul')
        except AttributeError:
            pass  # ì´ë¯¸ timezoneì´ ì„¤ì •ëœ ê²½ìš°
        except TypeError:
            df['date'] = df['date'].dt.tz_convert('Asia/Seoul')  # ì´ë¯¸ tz-awareì¸ ê²½ìš°
        
        df['weekday'] = df['date'].dt.day_name()
        
        # ì›”ìš”ì¼ë¶€í„° ì‹œì‘í•˜ëŠ” ìˆœì„œë¡œ ë³€ê²½
        weekday_order = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
        weekday_korean = {
            'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
            'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼',
            'Sunday': 'ì¼ìš”ì¼'
        }
        
        weekday_stats = df.groupby('weekday').agg({
            'views': ['mean', 'sum', 'count'],
            'comments': ['mean', 'sum'],
            'likes': ['mean', 'sum'],
            'engagement_score': 'mean'
        }).round(2)
        
        weekday_stats.columns = ['í‰ê· _ì¡°íšŒìˆ˜', 'ì´_ì¡°íšŒìˆ˜', 'ì˜ìƒìˆ˜', 'í‰ê· _ëŒ“ê¸€ìˆ˜', 'ì´_ëŒ“ê¸€ìˆ˜', 
                                'í‰ê· _ì¢‹ì•„ìš”ìˆ˜', 'ì´_ì¢‹ì•„ìš”ìˆ˜', 'í‰ê· _ì°¸ì—¬ë„']
                                
        # ìš”ì¼ ì´ë¦„ì„ í•œê¸€ë¡œ ë³€í™˜
        weekday_stats.index = weekday_stats.index.map(weekday_korean)
        # ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ ìˆœì„œë¡œ ì •ë ¬
        weekday_stats = weekday_stats.reindex(weekday_order)
        
        return weekday_stats
    
    def calculate_hourly_stats(self, df):
        # date ì»¬ëŸ¼ì´ datetime íƒ€ì…ì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜
        df['date'] = pd.to_datetime(df['date'])
        try:
            df['date'] = df['date'].dt.tz_localize(None).tz_localize('UTC').tz_convert('Asia/Seoul')
        except AttributeError:
            pass  # ì´ë¯¸ timezoneì´ ì„¤ì •ëœ ê²½ìš°
        except TypeError:
            df['date'] = df['date'].dt.tz_convert('Asia/Seoul')  # ì´ë¯¸ tz-awareì¸ ê²½ìš°
        
        df['hour'] = df['date'].dt.hour
        
        hourly_stats = df.groupby('hour').agg({
            'views': ['mean', 'sum', 'count'],
            'comments': ['mean', 'sum'],
            'likes': ['mean', 'sum'],
            'engagement_score': 'mean'
        }).round(2)
        
        hourly_stats.columns = ['í‰ê· _ì¡°íšŒìˆ˜', 'ì´_ì¡°íšŒìˆ˜', 'ì˜ìƒìˆ˜', 'í‰ê· _ëŒ“ê¸€ìˆ˜', 'ì´_ëŒ“ê¸€ìˆ˜',
                               'í‰ê· _ì¢‹ì•„ìš”ìˆ˜', 'ì´_ì¢‹ì•„ìš”ìˆ˜', 'í‰ê· _ì°¸ì—¬ë„']
        
        # ëª¨ë“  ì‹œê°„ëŒ€ í¬í•¨
        all_hours = pd.DataFrame(index=range(24))
        hourly_stats = hourly_stats.reindex(all_hours.index).fillna(0)
        
        return hourly_stats
        

    def create_dashboard(self, df):
        st.title(f"ğŸ“Š YouTube í‚¤ì›Œë“œ ë¶„ì„: {self.keyword}")
        
        # date ì»¬ëŸ¼ ìƒì„±ì„ ê°€ì¥ ë¨¼ì € ìˆ˜í–‰í•˜ê³  timezone ì²˜ë¦¬
        df = df.copy()  # ì›ë³¸ ë°ì´í„° ë³´í˜¸
        df['date'] = pd.to_datetime(df['publishedAt'])
        
        # 1. ì£¼ìš” ì§€í‘œ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ë¶„ì„ ì˜ìƒ", f"{len(df):,}ê°œ")
        with col2:
            st.metric("ì´ ì¡°íšŒìˆ˜", f"{df['views'].sum():,}íšŒ")
        with col3:
            st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{int(df['likes'].mean()):,}ê°œ")
        with col4:
            st.metric("í‰ê·  ëŒ“ê¸€", f"{int(df['comments'].mean()):,}ê°œ")
        
    # 2. í†µê³„ ê³„ì‚°
        weekday_stats = self.calculate_weekday_stats(df.copy())
        hourly_stats = self.calculate_hourly_stats(df.copy())
        
        # AI ë¶„ì„ìš© ë°ì´í„°ì— ì‹œê°„ í†µê³„ ì¶”ê°€í•  ë•Œ ë°ì´í„° ê²€ì¦ ì¶”ê°€
        weekday_data = weekday_stats.to_dict('index')
        hourly_data = hourly_stats.to_dict('index')
        
        self.temporal_stats = {
            'weekday_stats': {
                'data': weekday_stats.to_dict('index'),
                'max_views_day': weekday_stats['í‰ê· _ì¡°íšŒìˆ˜'].idxmax(),
                'max_views_value': weekday_stats['í‰ê· _ì¡°íšŒìˆ˜'].max(),
                'max_engagement_day': weekday_stats['í‰ê· _ì°¸ì—¬ë„'].idxmax(),
                'weekday_engagement': weekday_stats['í‰ê· _ì°¸ì—¬ë„'].to_dict(),  # ì „ì²´ ìš”ì¼ë³„ ì°¸ì—¬ë„ ì¶”ê°€
                'weekday_views': weekday_stats['í‰ê· _ì¡°íšŒìˆ˜'].to_dict()  # ì „ì²´ ìš”ì¼ë³„ ì¡°íšŒìˆ˜ ì¶”ê°€
            },
            'hourly_stats': {
                'data': hourly_stats.to_dict('index'),
                'max_views_hour': int(hourly_stats['í‰ê· _ì¡°íšŒìˆ˜'].idxmax()),
                'max_views_value': hourly_stats['í‰ê· _ì¡°íšŒìˆ˜'].max(),
                'max_engagement_hour': int(hourly_stats['í‰ê· _ì°¸ì—¬ë„'].idxmax()),
                'hourly_engagement': hourly_stats['í‰ê· _ì°¸ì—¬ë„'].to_dict(),  # ì „ì²´ ì‹œê°„ëŒ€ë³„ ì°¸ì—¬ë„ ì¶”ê°€
                'hourly_views': hourly_stats['í‰ê· _ì¡°íšŒìˆ˜'].to_dict()  # ì „ì²´ ì‹œê°„ëŒ€ë³„ ì¡°íšŒìˆ˜ ì¶”ê°€
            }
        }
        
        # 3. ì‹œê³„ì—´ ë¶„ì„ ì‹œê°í™”
        st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ë¶„ì„")
        
        # 3-1. ìš”ì¼ë³„ ë¶„ì„
        st.markdown("#### ğŸ“… ìš”ì¼ë³„ ë¶„ì„")
        self.visualize_weekday_stats(weekday_stats)
        
        # 3-2. ì‹œê°„ëŒ€ë³„ ë¶„ì„
        st.markdown("#### ğŸ•’ ì‹œê°„ëŒ€ë³„ ë¶„ì„")
        self.visualize_hourly_stats(hourly_stats)
        
        # 4. ìƒìœ„ ì˜ìƒ í…Œì´ë¸”
        st.subheader("ğŸ† ìƒìœ„ 20ê°œ ì˜ìƒ")
        cols = st.columns(4)  # í•œ í–‰ì— 4ê°œì˜ ì˜ìƒ í‘œì‹œ
        
        videos_data = df.nlargest(20, 'engagement_score').to_dict('records')
        
        for idx, video in enumerate(videos_data):
           with cols[idx % 4]:
               try:
                   # ì¸ë„¤ì¼ URL ì˜ˆì™¸ ì²˜ë¦¬
                   thumbnail_url = f"https://img.youtube.com/vi/{video['id']}/maxresdefault.jpg"
                   # ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                   response = requests.head(thumbnail_url)
                   if response.status_code != 200:
                       thumbnail_url = f"https://img.youtube.com/vi/{video['id']}/hqdefault.jpg"
               except:
                   thumbnail_url = f"https://img.youtube.com/vi/{video['id']}/hqdefault.jpg"
                   
               video_url = f"https://www.youtube.com/watch?v={video['id']}"
               
               # ì¹´ë“œ ìŠ¤íƒ€ì¼ì˜ ë ˆì´ì•„ì›ƒ
               st.markdown(f"""
                   <div style="border: 1px solid #ddd; padding: 10px; border-radius: 5px; margin-bottom: 20px;">
                       <a href="{video_url}" target="_blank">
                           <img src="{thumbnail_url}" style="width: 100%; border-radius: 5px;">
                       </a>
                       <a href="{video_url}" target="_blank" style="text-decoration: none; color: #1e88e5;">
                           <p style="margin: 10px 0; font-size: 0.9em; font-weight: bold;">{video['title']}</p>
                       </a>
                       <p style="margin: 5px 0; font-size: 0.8em;">ğŸ‘€ ì¡°íšŒìˆ˜: {video['views']:,}</p>
                       <p style="margin: 5px 0; font-size: 0.8em;">ğŸ‘ ì¢‹ì•„ìš”: {video['likes']:,}</p>
                       <p style="margin: 5px 0; font-size: 0.8em;">ğŸ’¬ ëŒ“ê¸€: {video['comments']:,}</p>
                       <p style="margin: 5px 0; font-size: 0.8em;">ğŸ“Š ì°¸ì—¬ë„: {video['engagement_score']:.2f}</p>
                   </div>
               """, unsafe_allow_html=True)

        # 5. ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„
        st.subheader("ğŸ” ì œëª© í‚¤ì›Œë“œ ë¶„ì„")
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            font_path = os.path.join(current_dir, 'Pretendard-Bold.ttf')

            wordcloud = WordCloud(
                width=800, 
                height=400,
                background_color='white',
                font_path=font_path,
                prefer_horizontal=0.7
            ).generate(' '.join(df['title']))

            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)

        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•œê¸€ í°íŠ¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    def visualize_weekday_stats(self, weekday_stats):
        col1, col2 = st.columns(2)
        
        with col1:
            fig_weekday_views = go.Figure()
            fig_weekday_views.add_trace(go.Bar(
                x=weekday_stats.index,
                y=weekday_stats['í‰ê· _ì¡°íšŒìˆ˜'],
                marker_color='#1976D2'
            ))
            fig_weekday_views.update_layout(
                title='ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜',
                xaxis_title='ìš”ì¼',
                yaxis_title='í‰ê·  ì¡°íšŒìˆ˜',
                height=400
            )
            st.plotly_chart(fig_weekday_views, use_container_width=True)
        
        with col2:
            fig_weekday_comments = go.Figure()
            fig_weekday_comments.add_trace(go.Bar(
                x=weekday_stats.index,
                y=weekday_stats['í‰ê· _ëŒ“ê¸€ìˆ˜'],
                marker_color='#FFA726'
            ))
            fig_weekday_comments.update_layout(
                title='ìš”ì¼ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜',
                xaxis_title='ìš”ì¼',
                yaxis_title='í‰ê·  ëŒ“ê¸€ìˆ˜',
                height=400
            )
            st.plotly_chart(fig_weekday_comments, use_container_width=True)
    
    def visualize_hourly_stats(self, hourly_stats):
        col3, col4 = st.columns(2)
        
        with col3:
            fig_hourly_views = go.Figure()
            fig_hourly_views.add_trace(go.Bar(
                x=hourly_stats.index,
                y=hourly_stats['í‰ê· _ì¡°íšŒìˆ˜'],
                marker_color='#1976D2'
            ))
            fig_hourly_views.update_layout(
                title='ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜',
                xaxis_title='ì‹œê°„',
                yaxis_title='í‰ê·  ì¡°íšŒìˆ˜',
                height=400,
                xaxis=dict(
                    tickmode='array',
                    ticktext=[f'{i:02d}ì‹œ' for i in range(24)],
                    tickvals=list(range(24)),
                    range=[-0.5, 23.5]
                )
            )
            st.plotly_chart(fig_hourly_views, use_container_width=True)
        
        with col4:
            fig_hourly_comments = go.Figure()
            fig_hourly_comments.add_trace(go.Bar(
                x=hourly_stats.index,
                y=hourly_stats['í‰ê· _ëŒ“ê¸€ìˆ˜'],
                marker_color='#FFA726'
            ))
            fig_hourly_comments.update_layout(
                title='ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜',
                xaxis_title='ì‹œê°„',
                yaxis_title='í‰ê·  ëŒ“ê¸€ìˆ˜',
                height=400,
                xaxis=dict(
                    tickmode='array',
                    ticktext=[f'{i:02d}ì‹œ' for i in range(24)],
                    tickvals=list(range(24)),
                    range=[-0.5, 23.5]
                )
            )
            st.plotly_chart(fig_hourly_comments, use_container_width=True)        
            
    def run_analysis(self):
        try:
            if not self.youtube_api_key:
                st.error("YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return
                
            st.info("YouTube ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...")
            youtube = build("youtube", "v3", developerKey=self.youtube_api_key)
            
            # API í• ë‹¹ëŸ‰ ì´ˆê³¼ í™•ì¸
            try:
                videos_data = self.collect_videos_data(youtube)
            except Exception as e:
                if "ì¼ì¼ API í• ë‹¹ëŸ‰ ì´ˆê³¼" in str(e):
                    st.error("YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return
                raise e
            
            if not videos_data:
                st.error("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            df = pd.DataFrame(videos_data)
            self.create_dashboard(df)
            
            # Claude AI ë¶„ì„ ì‹¤í–‰
            if self.claude_api_key:
                self.run_ai_analysis(df)
            
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


    def format_analysis_response(self, text):
        """Claude API ì‘ë‹µì„ ê°€ë…ì„± ìˆê²Œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜"""
        formatted_text = ""
        lines = text.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:  # ë¹ˆ ì¤„ ì²˜ë¦¬
                formatted_text += "\n"
            elif any(emoji in line for emoji in ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£']):
                formatted_text += f"\n\n### {line}\n"
            elif line.startswith('â–¶ï¸'):
                formatted_text += f"\n#### {line}\n"
            elif line.startswith('####'):
                formatted_text += f"\n{line}\n"
            elif line.startswith('â€¢'):
                formatted_text += f"\n    * {line[1:].strip()}\n"
            elif line.strip().startswith('-'):
                formatted_text += f"\n        - {line[1:].strip()}\n"
            else:
                formatted_text += f"{line}\n"
        
        return formatted_text            

    def run_ai_analysis(self, df):
        st.subheader("ğŸ¤– AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
        
        if not self.claude_api_key:
            st.warning("Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
            
        with st.spinner("AI ë¶„ì„ì„ ìˆ˜í–‰ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                client = Anthropic(api_key=self.claude_api_key)
                
                # DataFrameì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ê¸° ì „ì— ì „ì²˜ë¦¬
                df_for_analysis = df.copy()
                df_for_analysis['date'] = pd.to_datetime(df_for_analysis['publishedAt']).dt.strftime('%Y-%m-%d %H:%M:%S')
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                analysis_data = df_for_analysis[[
                    'title', 'views', 'likes', 'comments', 
                    'engagement_score', 'date'
                ]].to_dict('records')
                
                # 4ê°œì˜ í”„ë¡¬í”„íŠ¸ë¡œ ë‚˜ëˆ„ì–´ ì‹¤í–‰
                first_response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{
                        "role": "user", 
                        "content": self.first_part_prompt(analysis_data)
                    }]
                )
                
                time.sleep(3)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
    
                second_response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{
                        "role": "user", 
                        "content": self.second_part_prompt(analysis_data)
                    }]
                )
                
                time.sleep(3)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
    
                third_response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{
                        "role": "user", 
                        "content": self.third_part_prompt(analysis_data)
                    }]
                )
                
                time.sleep(3)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
    
                fourth_response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{
                        "role": "user", 
                        "content": self.fourth_part_prompt(analysis_data)
                    }]
                )
    
                # ê²°ê³¼ í‘œì‹œ
                if hasattr(first_response.content[0], 'text'):
                    # ìƒˆë¡œìš´ API ì‘ë‹µ í˜•ì‹
                    analysis_parts = [
                        first_response.content[0].text,
                        second_response.content[0].text,
                        third_response.content[0].text,
                        fourth_response.content[0].text
                    ]
                else:
                    # ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹
                    analysis_parts = [
                        first_response.content,
                        second_response.content,
                        third_response.content,
                        fourth_response.content
                    ]
    
                # ê° ë¶€ë¶„ì„ ìˆœì°¨ì ìœ¼ë¡œ í‘œì‹œ
                for i, part in enumerate(analysis_parts):
                    st.markdown(self.format_analysis_response(part))
                    if i < len(analysis_parts) - 1:  # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ì•„ë‹ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶”ê°€
                        st.markdown("---")
                
            except Exception as e:
                st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.write("ìƒì„¸ ì˜¤ë¥˜:", e)

    def first_part_prompt(self, analysis_data):
        return f"""ë‹¹ì‹ ì€ YouTube ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì²« ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

    {json.dumps(analysis_data, ensure_ascii=False, indent=2)}

1ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì„±ê³¼ íŒ¨í„´
â–¶ï¸ ì¡°íšŒìˆ˜ ìƒìœ„ 25% ì˜ìƒ íŠ¹ì§•
 #### ì œëª© íŒ¨í„´ ë¶„ì„:
    â€¢ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
        - ì‚¬ìš© ë¹ˆë„ê°€ ë†’ì€ í•µì‹¬ í‚¤ì›Œë“œ
        - í‚¤ì›Œë“œ ì¡°í•© íŒ¨í„´
        - ì„±ê³¼ë³„ í‚¤ì›Œë“œ ë¶„í¬
    â€¢ ì œëª© êµ¬ì¡°ì˜ íŠ¹ì§•
        - íš¨ê³¼ì ì¸ ì œëª© ê¸¸ì´
        - ì£¼ìš” ë¬¸ì¥ êµ¬ì„± íŒ¨í„´
        - ì‹œì²­ì í˜¸ì‘ì´ ë†’ì€ êµ¬ì¡°
    â€¢ íš¨ê³¼ì ì¸ ì œëª© ì‚¬ë¡€
        - ëŒ€í‘œì  ì„±ê³µ ì‚¬ë¡€ ë¶„ì„
        - ê³µí†µëœ ì„±ê³µ ìš”ì¸
        - ì‹¤ì œ ì ìš© ë°©ì•ˆ

 #### ì„±ê³µì ì¸ ì˜ìƒì˜ ê³µí†µì :
    â€¢ ì½˜í…ì¸  êµ¬ì„± íŠ¹ì§•
        - íš¨ê³¼ì ì¸ êµ¬ì„± ìš”ì†Œ
        - ì‹œì²­ì ë°˜ì‘ì´ ì¢‹ì€ í¬ë§·
        - í•µì‹¬ ì„±ê³µ ìš”ì¸
    â€¢ ì‹œì²­ì ë°˜ì‘ íŒ¨í„´
        - ê¸ì •ì  ë°˜ì‘ ìš”ì¸
        - ì°¸ì—¬ë„ ì¦ê°€ ìš”ì†Œ
        - ì‹œì²­ì í–‰ë™ ë¶„ì„
    â€¢ ì°¨ë³„í™” ìš”ì†Œ
        - ë…íŠ¹í•œ ê°•ì  ë¶„ì„
        - ê²½ìŸë ¥ ìˆëŠ” íŠ¹ì§•
        - ë²¤ì¹˜ë§ˆí‚¹ í¬ì¸íŠ¸

ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
4. 'ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„', 'ì‹œì²­ì ê´€ì‹¬ì„ ë„ëŠ” í‚¤ì›Œë“œ'ì—ì„œëŠ” ë¶„ì„í•  í‚¤ì›Œë“œëŠ” ì œì™¸í•˜ê³  ê·¸ì™¸ í‚¤ì›Œë“œë¥¼ ìœ„ì£¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ë§ˆì§€ë§‰ ë¶€ë¶„ì— ë¶„ì„ ê²°ê³¼ ë°ì´í„°ì— ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì¸ì— ëŒ€í•œ ê°€ì„¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ê° í•­ëª©ì€ 20ê°œì˜ ì˜ìƒë“¤ì˜ ì˜ˆì‹œì™€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•´ì„œ ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    def second_part_prompt(self, analysis_data):
        return f"""ì´ì–´ì„œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‘ ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:
    
    {json.dumps(analysis_data, ensure_ascii=False, indent=2)}
    
2ï¸âƒ£ ìµœì í™” ì¸ì‚¬ì´íŠ¸
â–¶ï¸ ì œëª© ìµœì í™” ì „ëµ
 #### íš¨ê³¼ì ì¸ ì œëª© êµ¬ì„± ìš”ì†Œ:
    â€¢ í•µì‹¬ í‚¤ì›Œë“œ
        - í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ
        - íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ ìˆœì„œ
        - í‚¤ì›Œë“œ ì¡°í•© ì „ëµ
    â€¢ êµ¬ì¡°ì  íŠ¹ì§•
        - ìµœì ì˜ ì œëª© êµ¬ì¡°
        - íš¨ê³¼ì ì¸ ë¬¸ì¥ íŒ¨í„´
        - ì‹œì²­ì ì£¼ëª©ë„ ë†’ì€ í˜•ì‹

 #### ì‹œì²­ì ê´€ì‹¬ì„ ë„ëŠ” í‚¤ì›Œë“œ:
    â€¢ ìƒìœ„ ì„±ê³¼ í‚¤ì›Œë“œ
        - ì¡°íšŒìˆ˜ ì—°ê´€ í‚¤ì›Œë“œ
        - ì°¸ì—¬ë„ ì—°ê´€ í‚¤ì›Œë“œ
        - ì„±ê³¼ë³„ í‚¤ì›Œë“œ ë¶„ì„
    â€¢ ì‹œì²­ì ë°˜ì‘ì´ ì¢‹ì€ í‘œí˜„
        - íš¨ê³¼ì ì¸ ë¬¸êµ¬ íŒ¨í„´
        - ê°ì • ë°˜ì‘ ìœ ë„ ìš”ì†Œ
        - ì°¸ì—¬ ìœ ë„ í‘œí˜„
    â€¢ íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„
        - ì‹œê¸°ë³„ ìœ íš¨ í‚¤ì›Œë“œ
        - í™œìš© ì „ëµ ì œì•ˆ

ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
4. 'ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„', 'ì‹œì²­ì ê´€ì‹¬ì„ ë„ëŠ” í‚¤ì›Œë“œ'ì—ì„œëŠ” ë¶„ì„í•  í‚¤ì›Œë“œëŠ” ì œì™¸í•˜ê³  ê·¸ì™¸ í‚¤ì›Œë“œë¥¼ ìœ„ì£¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ê° í•­ëª©ë§ˆë‹¤ ë¶„ì„ ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ê²°ê³¼ ë°ì´í„°ì— ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì¸ì— ëŒ€í•œê°€ì„¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ê° í•­ëª©ì€ 20ê°œì˜ ì˜ìƒë“¤ì˜ ì˜ˆì‹œì™€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•´ì„œ ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    def third_part_prompt(self, analysis_data):
        # temporal_statsì˜ ìƒì„¸ ë°ì´í„° í™œìš©
        weekday_stats = self.temporal_stats['weekday_stats']
        hourly_stats = self.temporal_stats['hourly_stats']
        
        # ìš”ì¼ë³„, ì‹œê°„ë³„ ì „ì²´ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ… (ëŒ“ê¸€ ìˆ˜ ì¤‘ì‹¬ìœ¼ë¡œ ë³€ê²½)
        weekday_performance = "\n".join([
            f"    - {day}: í‰ê·  ì¡°íšŒìˆ˜ {views:,.0f}, í‰ê·  ëŒ“ê¸€ìˆ˜ {weekday_stats['data'][day]['í‰ê· _ëŒ“ê¸€ìˆ˜']:.1f}"
            for day, views in weekday_stats['weekday_views'].items()
        ])
        
        hourly_performance = "\n".join([
            f"    - {hour}ì‹œ: í‰ê·  ì¡°íšŒìˆ˜ {views:,.0f}, í‰ê·  ëŒ“ê¸€ìˆ˜ {hourly_stats['data'][hour]['í‰ê· _ëŒ“ê¸€ìˆ˜']:.1f}"
            for hour, views in hourly_stats['hourly_views'].items()
        ])

        # ìµœëŒ€ê°’ ê³„ì‚° ë¡œì§ ìˆ˜ì • (ëŒ“ê¸€ ìˆ˜ ê¸°ì¤€)
        max_comments_day = max(weekday_stats['data'].items(), key=lambda x: x[1]['í‰ê· _ëŒ“ê¸€ìˆ˜'])[0]
        max_comments_hour = int(max(hourly_stats['data'].items(), key=lambda x: x[1]['í‰ê· _ëŒ“ê¸€ìˆ˜'])[0])
        max_comments_day_value = weekday_stats['data'][max_comments_day]['í‰ê· _ëŒ“ê¸€ìˆ˜']
        max_comments_hour_value = hourly_stats['data'][max_comments_hour]['í‰ê· _ëŒ“ê¸€ìˆ˜']

        content = f"""ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”.
        ì‹¤ì œ ë°ì´í„° ë¶„ì„ ê²°ê³¼:
        
        ìš”ì¼ë³„ ì„±ê³¼:
    {weekday_performance}

        ì‹œê°„ëŒ€ë³„ ì„±ê³¼:
    {hourly_performance}

        ì£¼ìš” ì„±ê³¼ ì§€í‘œ:
        - ìµœê³  ì¡°íšŒìˆ˜ ìš”ì¼: {weekday_stats['max_views_day']} ({weekday_stats['max_views_value']:,.0f}íšŒ)
        - ìµœë‹¤ ëŒ“ê¸€ ìš”ì¼: {max_comments_day} ({max_comments_day_value:.1f}ê°œ)
        - ìµœê³  ì¡°íšŒìˆ˜ ì‹œê°„: {hourly_stats['max_views_hour']}ì‹œ ({hourly_stats['max_views_value']:,.0f}íšŒ)
        - ìµœë‹¤ ëŒ“ê¸€ ì‹œê°„: {max_comments_hour}ì‹œ ({max_comments_hour_value:.1f}ê°œ)
        
        ë¶„ì„í•  ë°ì´í„°:
        {json.dumps(analysis_data, ensure_ascii=False, indent=2)}

3ï¸âƒ£ ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
â–¶ï¸ ì—…ë¡œë“œ ì „ëµ
 #### ìµœì ì˜ ì—…ë¡œë“œ ì‹œê°„ëŒ€:
    â€¢ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„
        - ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜ ë¶„ì„
        - ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜ ë¶„ì„
        - ìµœê³  ì„±ê³¼ë¥¼ ë³´ì¸ êµ¬ì²´ì ì¸ ì‹œê°„ëŒ€ ëª…ì‹œ
    â€¢ ì‹œì²­ì ì°¸ì—¬ê°€ ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€
        - ëŒ“ê¸€ ì‘ì„±ì´ ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€ ë¶„ì„
        - êµ¬ì²´ì ì¸ ìµœì  ì‹œê°„ëŒ€ ë„ì¶œ
        - ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ìˆ˜ ì°¨ì´ì˜ ì •ëŸ‰ì  ë¶„ì„

 #### ìš”ì¼ë³„ ì„±ê³¼ ë¶„ì„:
    â€¢ êµ¬ì²´ì ì¸ ìš”ì¼ë³„ ì„±ê³¼
        - ê° ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜ ë¶„ì„
        - ê° ìš”ì¼ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜ ë¶„ì„
        - ìµœì ì˜ ì—…ë¡œë“œ ìš”ì¼ ë„ì¶œ
    â€¢ ìš”ì¼ë³„ ì‹œì²­ì ì°¸ì—¬ íŒ¨í„´
        - ëŒ“ê¸€ ì‘ì„±ì´ ê°€ì¥ í™œë°œí•œ ìš”ì¼ ë¶„ì„
        - ìµœê³ /ìµœì € ëŒ“ê¸€ìˆ˜ë¥¼ ê¸°ë¡í•œ ìš”ì¼
        - ìš”ì¼ë³„ ì‹œì²­ì ì°¸ì—¬ë„ ì°¨ì´ì˜ ì •ëŸ‰ì  ë¶„ì„

 #### ì‹œì¦Œë³„ íŠ¸ë Œë“œ:
    â€¢ ê³„ì ˆë³„ ì„±ê³¼ ë¹„êµ
        - ê³„ì ˆë³„ ì¡°íšŒìˆ˜ì™€ ëŒ“ê¸€ìˆ˜ ì°¨ì´
        - ì‹œì¦Œë³„ ì‹œì²­ì ì°¸ì—¬ íŠ¹ì„±
        - ì‹œì¦Œ ë§ì¶¤ ì „ëµ
    â€¢ íŠ¹ì • ê¸°ê°„ ì„±ê³¼ íŒ¨í„´
        - ì£¼ìš” ì„±ê³¼ êµ¬ê°„ ë¶„ì„
        - ì„±ê³µ ìš”ì¸ ë„ì¶œ
        - ì „ëµì  í™œìš© ë°©ì•ˆ
    â€¢ ì¥ê¸°ì  íŠ¸ë Œë“œ íŒ¨í„´
        - ì—°ê°„ íŠ¸ë Œë“œ ë¶„ì„
        - ì„±ì¥ íŒ¨í„´ ë„ì¶œ
        - ì¥ê¸° ì „ëµ ìˆ˜ë¦½

ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ëª¨ë“  ìˆ˜ì¹˜ëŠ” êµ¬ì²´ì ì¸ ê°’ìœ¼ë¡œ ì œì‹œ (ì˜ˆ: 'í‰ê·  47.2ê°œì˜ ëŒ“ê¸€', '2.3ë°° ë†’ì€ ì¡°íšŒìˆ˜')
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
4. ì‹œê°„ì€ 24ì‹œê°„ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•´ì£¼ì„¸ìš”. (ì˜ˆ: '15ì‹œ~19ì‹œ')
5. ìµœì  ì‹œê°„ëŒ€ì™€ ìš”ì¼ì€ ë°ì´í„°ìƒ ê°€ì¥ ë†’ì€ ìˆ˜ì¹˜ë¥¼ ë³´ì¸ ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”
6. ì¸ê²Œì´ì§€ë¨¼íŠ¸ ìŠ¤ì½”ì–´ ëŒ€ì‹  ìˆœìˆ˜ ëŒ“ê¸€ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì²­ì ì°¸ì—¬ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
7. ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ í† ëŒ€ë¡œ ì „ëµì ì¸ ì œì–¸ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ê³  ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

        return content

    def fourth_part_prompt(self, analysis_data):
        return f"""ì´ì–´ì„œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë„¤ ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:
        
    {json.dumps(analysis_data, ensure_ascii=False, indent=2)}

4ï¸âƒ£ ì½˜í…ì¸  ì œì‘ ê°€ì´ë“œ
â–¶ï¸ í¬ë§· ìµœì í™”
 #### ì„±ê³¼ê°€ ì¢‹ì€ ì½˜í…ì¸  ìœ í˜•:
    â€¢ ìƒìœ„ ì„±ê³¼ ì½˜í…ì¸  ë¶„ì„
        - í•µì‹¬ ì„±ê³µ ìš”ì¸
        - í¬ë§·ë³„ ì„±ê³¼ ë¹„êµ
        - ìµœì í™” í¬ì¸íŠ¸
    â€¢ ê³µí†µëœ êµ¬ì„± ìš”ì†Œ
        - íš¨ê³¼ì ì¸ êµ¬ì„± ë°©ì‹
        - í•µì‹¬ êµ¬ì„± ìš”ì†Œ
        - ì‹œì²­ì ì„ í˜¸ íŒ¨í„´
    â€¢ ì°¨ë³„í™” í¬ì¸íŠ¸
        - ë…íŠ¹í•œ ê°•ì  ë¶„ì„
        - ê²½ìŸë ¥ ìš”ì†Œ
        - ì°¨ë³„í™” ì „ëµ

â–¶ï¸ ëŒ“ê¸€ ë¶„ì„ì„ í†µí•œ ê¸°íš
#### ëŒ“ê¸€ ë‚´ìš© ë¶„ì„:
    â€¢ ì£¼ìš” í‚¤ì›Œë“œ ë° í† í”½
        - ìì£¼ ì–¸ê¸‰ë˜ëŠ” í‚¤ì›Œë“œ
        - ì£¼ìš” ê´€ì‹¬ì‚¬ ë° ì£¼ì œ
    â€¢ ì‹œì²­ì ê°ì •/íƒœë„
        - ê¸ì •ì  ë°˜ì‘ íŒ¨í„´
        - ë¶€ì •ì  í”¼ë“œë°± ë¶„ì„
    â€¢ ì‹œì²­ì ë‹ˆì¦ˆ íŒŒì•…
        - ìì£¼ ë‚˜ì˜¤ëŠ” ì§ˆë¬¸
        - ìš”ì²­ì‚¬í•­ ë° ì œì•ˆ

ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
4. 'í•µì‹¬ í‚¤ì›Œë“œ'ì— ëŒ€í•´ ë¶„ì„í•  ë•ŒëŠ” ë¶„ì„í•  í‚¤ì›Œë“œëŠ” ì œì™¸í•˜ê³  ê·¸ì™¸ í‚¤ì›Œë“œë¥¼ ìœ„ì£¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ì‹œì²­ìë“¤ì˜ ëŒ“ê¸€ ë¶„ì„ ì„¹ì…˜ì˜ ë‚´ìš©ì´ ì¢€ë” ë””í…Œì¼í•˜ê²Œ êµ¬ì„±í•˜ê³  ì‹¤ì œ ëŒ“ê¸€ ì˜ˆì‹œë¥¼ ë“¤ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
6. ëŒ“ê¸€ ë¶„ì„ ì‹œ ë¶€ì • ëŒ“ê¸€ê³¼ ê¸ì •ì  ëŒ“ê¸€ì€ ê°ê° ì–´ë–¤ ë‚´ìš©ì´ ë§ì•˜ëŠ”ì§€ë„ ë³´ì—¬ì£¼ì„¸ìš”.
7. ëŒ“ê¸€ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ í† ëŒ€ë¡œ ì‹œì²­ìë“¤ì´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” í¬ì¸íŠ¸ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ê° í•­ëª©ì€ 20ê°œì˜ ì˜ìƒë“¤ì˜ ì˜ˆì‹œì™€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•´ì„œ ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    def run(self):
        """ì•± ì‹¤í–‰"""
        if not st.session_state.logged_in:
            return
            
        if not self.youtube_api_key:
            st.error("YouTube API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        if not self.keyword:  # í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ì„ ë•Œ ì†Œê°œ í˜ì´ì§€ í‘œì‹œ
            st.header("â›ï¸ìœ íŠœë¸Œ ì¸ì‚¬ì´íŠ¸ ë§ˆì´ë‹ğŸ’")
            
            # ì„¹ì…˜ 1: ì†Œê°œ
            st.subheader("ğŸ¤“í”¼ë¶€ê³¼ ì¸í•˜ìš°ìŠ¤ ë§ˆì¼€í„° íƒœíŒ€ì¥ì…ë‹ˆë‹¤!")
            st.markdown("""
            ì—¬ëŸ¬ë¶„ì€ ì½˜í…ì¸  ê¸°íšì„ ì–´ë–»ê²Œ í•˜ì‹œë‚˜ìš”?  
            ì €ëŠ” ìœ íŠœë¸ŒAPIë¥¼ í†µí•´ ì–»ì€ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ”ë°ìš”.  
            ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ì´ìš©í•´ ì¸ê¸° ì˜ìƒì˜ ì œëª© íŒ¨í„´ê³¼ ëŒ“ê¸€ í‚¤ì›Œë“œë¥¼  
            Claude aië¡œ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.  
            ìœ íŠœë¸Œ ì¸ì‹¸ì´íŠ¸ ë§ˆì´ë‹ì€ ì´ëŸ¬í•œ ë¶„ì„ ê³¼ì •ì„ ìë™í™”í•œ ë„êµ¬ì…ë‹ˆë‹¤.  
            ì‹¤ë¬´ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì½˜í…ì¸  ì¸ì‚¬ì´íŠ¸ë¥¼ ê°€ì ¸ê°€ì„¸ìš”!
            
            * ğŸ“Š ìƒì„¸í•œ ë°ì´í„° ë¶„ì„ê³¼ ì‹œê°í™”
            * ğŸ¤– Claude AIë¥¼ í™œìš©í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
            * â° ìµœì ì˜ ì—…ë¡œë“œ ì‹œê°„ ë¶„ì„
            * ğŸ“ˆ ì‹œì²­ì ëŒ“ê¸€ ë¶„ì„
            """)
            
            # ì„¹ì…˜ 2: ì‚¬ìš© ë°©ë²•
            st.subheader("ğŸ“ ì‚¬ìš©ë²•")
            st.markdown("""
            1ï¸âƒ£ **ë¶„ì„ ì„¤ì •**
            * ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”
            * ê²€ìƒ‰í•  ì˜ìƒ ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” (10~100ê°œ)
            * ë¶„ì„ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš” (1~24ê°œì›”)
            
            2ï¸âƒ£ **ë¶„ì„ ì‹œì‘**
            * ëª¨ë“  ì„¤ì •ì„ ì™„ë£Œí•œ í›„ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
            * ë¶„ì„ì—ëŠ” ì•½ 1~2ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤
            
            3ï¸âƒ£ **ê²°ê³¼ í™•ì¸**
            * ë°ì´í„° ê¸°ë°˜ ì„±ê³¼ íŒ¨í„´
            * ìµœì í™” ì¸ì‚¬ì´íŠ¸
            * ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            * ì½˜í…ì¸  ì œì‘ ê°€ì´ë“œ
            """)
            
            # ì œì•ˆ
            st.warning("""
            ğŸ“¢ **ì•Œë¦¼**
            * ì„±í˜•ì–´í”Œ ê²½ìŸì‚¬ ê°€ê²© ì¡°ì‚¬ ì•±ì´ ê³§ ì™„ì„±ë©ë‹ˆë‹¤. í•„ìš”í•˜ì‹  ë¶„ë“¤ê»˜ ë¬´ë£Œë¡œ ê³µìœ í•˜ê² ìŠµë‹ˆë‹¤.  
            * ë³‘ì› ë§ˆì¼€íŒ… ì§ˆë¬¸ ë§ì´ ì£¼ì‹œëŠ”ë°.. ì•„ëŠ” ì„ ì—ì„œ ìµœëŒ€í•œ ë‹µë³€ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.    
            * ì´ ì•±ì€ ê°œì¸ì ìœ¼ë¡œ ì—…ë¬´ì— í™œìš©í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.  
             ì½˜í…ì¸  ê¸°íšì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” ë¶„ë“¤ì„ ìœ„í•´ ë¬´ë£Œë¡œ ê³µìœ í•©ë‹ˆë‹¤.  
             ë¶€ì¡±í•œ ì ì´ ìˆë”ë¼ë„ ì´í•´í•´ì£¼ì‹œê³ , ì—…ë¬´ì— ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë˜ì…¨ìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.  
            * ë§ˆì¼€íŒ… ìë™í™” ê´€ë ¨ ì•„ì´ë””ì–´ í™˜ì˜í•©ë‹ˆë‹¤. bbachinco@gmail.com
            """)
            
            # ì£¼ì˜ì‚¬í•­
            st.warning("""
            âš ï¸ **ì£¼ì˜ì‚¬í•­**
            * ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì¶©ë¶„í•œ ìˆ˜ì˜ ì˜ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.  
            * YouTube APIëŠ” ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
            * Claude API ì”ì•¡ì´ ë¶€ì¡±í•  ê²½ìš° AI ë¶„ì„ì´ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """)
            
        elif st.sidebar.button("ë¶„ì„ ì‹œì‘", use_container_width=True):
            self.run_analysis()

if __name__ == "__main__":
    app = YouTubeAnalytics()
    app.run()
