import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from googleapiclient.discovery import build
from datetime import datetime, timedelta
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from anthropic import Anthropic
import json
import os
from dotenv import load_dotenv

class YouTubeAnalytics:
    def __init__(self):
            self.load_api_keys()
            st.set_page_config(page_title="YouTube ì½˜í…ì¸  ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
            
            # Custom CSS ì¶”ê°€
            st.markdown("""
                <style>
                    h3 {
                        margin-top: 40px;
                        margin-bottom: 20px;
                        color: #1e88e5;
                        font-size: 1.5em;
                    }
                    h4 {
                        margin-top: 25px;
                        margin-bottom: 15px;
                        color: #2196f3;
                        font-size: 1.2em;
                    }
                    ul {
                        margin-left: 20px;
                        margin-bottom: 15px;
                    }
                    li {
                        margin-bottom: 8px;
                    }
                </style>
            """, unsafe_allow_html=True)
            
            self.setup_sidebar()

    def load_api_keys(self):
        # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
        load_dotenv()
        self.youtube_api_key = os.getenv('YOUTUBE_API_KEY')
        self.claude_api_key = os.getenv('CLAUDE_API_KEY')
        
        # API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì—†ëŠ” ê²½ìš° Streamlit secretsì—ì„œ ì‹œë„
        if not self.youtube_api_key:
            try:
                self.youtube_api_key = st.secrets["YOUTUBE_API_KEY"]
            except:
                self.youtube_api_key = None
                
        if not self.claude_api_key:
            try:
                self.claude_api_key = st.secrets["CLAUDE_API_KEY"]
            except:
                self.claude_api_key = None

    def setup_sidebar(self):
        with st.sidebar:
            st.title("âš™ï¸ ì„¤ì •")
            
            # API í‚¤ ì…ë ¥ í•„ë“œ (ì´ë¯¸ ë¡œë“œëœ í‚¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ í‘œì‹œ)
            if not self.youtube_api_key:
                self.youtube_api_key = st.text_input("YouTube API Key", type="password")
            if not self.claude_api_key:
                self.claude_api_key = st.text_input("Claude API Key", type="password")
            
            self.keyword = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œ")
            self.max_results = st.slider("ê²€ìƒ‰í•  ìµœëŒ€ ì˜ìƒ ìˆ˜", 10, 100, 50)
            self.date_range = st.slider("ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 24, 12)

    def collect_videos_data(self, youtube):
        date_limit = (datetime.now() - timedelta(days=30 * self.date_range)).isoformat() + "Z"
        videos = []
        next_page_token = None
        
        while len(videos) < self.max_results:
            try:
                # 1. ê²€ìƒ‰ ìš”ì²­
                search_response = youtube.search().list(
                    q=self.keyword,
                    type="video",
                    part="id",
                    maxResults=min(50, self.max_results - len(videos)),
                    pageToken=next_page_token,
                    publishedAfter=date_limit
                ).execute()
                
                video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]
                
                # 2. ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                videos_response = youtube.videos().list(
                    part='snippet,statistics,contentDetails',
                    id=','.join(video_ids)
                ).execute()
                
                # 3. ë°ì´í„° ì²˜ë¦¬ ë° í•„í„°ë§
                for video in videos_response.get('items', []):
                    try:
                        stats = video['statistics']
                        views = int(stats.get('viewCount', 0))
                        
                        # 1000íšŒ ì´ìƒ ì¡°íšŒëœ ì˜ìƒë§Œ í¬í•¨
                        if views >= 1000:
                            videos.append({
                                'id': video['id'],
                                'title': video['snippet']['title'],
                                'publishedAt': video['snippet']['publishedAt'],
                                'description': video['snippet']['description'],
                                'views': views,
                                'likes': int(stats.get('likeCount', 0)),
                                'comments': int(stats.get('commentCount', 0)),
                                'tags': video['snippet'].get('tags', []),
                                'duration': video['contentDetails']['duration']
                            })
                    except Exception as e:
                        st.warning(f"ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        continue
                
                next_page_token = search_response.get('nextPageToken')
                if not next_page_token:
                    break
                    
            except Exception as e:
                st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                break
        
        return self.calculate_engagement_scores(videos)

    def calculate_engagement_scores(self, videos):
        if not videos:
            return []
            
        # ëŒ“ê¸€ ë¹„ìœ¨ ë¶„ì„ì„ í†µí•œ ì´ìƒì¹˜ ì œê±°
        comment_ratios = [
            (video['comments'] / video['views'] * 100) 
            for video in videos if video['views'] > 0
        ]
        avg_ratio = np.mean(comment_ratios)
        std_ratio = np.std(comment_ratios)
        threshold = avg_ratio + (2 * std_ratio)
        
        one_week_ago = datetime.now() - timedelta(days=7)
        
        processed_videos = []
        for video in videos:
            try:
                views = video['views']
                likes = video['likes']
                comments = video['comments']
                publish_date = datetime.strptime(
                    video['publishedAt'], 
                    '%Y-%m-%dT%H:%M:%SZ'
                )
                
                comment_ratio = (comments / views * 100) if views > 0 else 0
                
                # ë¹„ì •ìƒì ì¸ ëŒ“ê¸€ ë¹„ìœ¨ ì œì™¸
                if comment_ratio > threshold:
                    continue
                    
                like_ratio = (likes / views * 100) if views > 0 else 0
                recency_score = 1.2 if publish_date > one_week_ago else 1.0
                
                engagement_score = (
                    like_ratio + 
                    (comment_ratio * 3)  # ëŒ“ê¸€ ê°€ì¤‘ì¹˜ 3ë°°
                ) * recency_score
                
                video['engagement_score'] = engagement_score
                video['like_ratio'] = like_ratio
                video['comment_ratio'] = comment_ratio
                video['is_recent'] = publish_date > one_week_ago
                
                processed_videos.append(video)
                
            except Exception as e:
                st.warning(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ì¸ê²Œì´ì§€ë¨¼íŠ¸ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        return sorted(
            processed_videos, 
            key=lambda x: x['engagement_score'], 
            reverse=True
        )[:20]  # ìƒìœ„ 20ê°œë§Œ ë°˜í™˜

    def create_dashboard(self, df):
        st.title(f"ğŸ“Š YouTube í‚¤ì›Œë“œ ë¶„ì„: {self.keyword}")
        
        # 1. ì£¼ìš” ì§€í‘œ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ë¶„ì„ ì˜ìƒ", f"{len(df):,}ê°œ")
        with col2:
            st.metric("ì´ ì¡°íšŒìˆ˜", f"{df['views'].sum():,}íšŒ")
        with col3:
            st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{int(df['likes'].mean()):,}ê°œ")
        with col4:
            st.metric("í‰ê·  ëŒ“ê¸€", f"{int(df['comments'].mean()):,}ê°œ")
        
# 2. ì‹œê³„ì—´ ë¶„ì„
        st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ë¶„ì„")
        df['date'] = pd.to_datetime(df['publishedAt'])
        
        # 2-1. ì¼ìë³„ ì¶”ì´
        st.markdown("#### ğŸ“… ì¼ìë³„ ì¶”ì´")
        daily_stats = df.groupby(df['date'].dt.date).agg({
            'views': 'sum',
            'comments': 'sum'
        }).reset_index()
        
        # ì¼ìë³„ ì¡°íšŒìˆ˜ ì¶”ì´
        fig_daily_views = go.Figure()
        fig_daily_views.add_trace(go.Scatter(
            x=daily_stats['date'],
            y=daily_stats['views'],
            name='ì¡°íšŒìˆ˜',
            mode='lines+markers',
            line=dict(color='#1976D2')
        ))
        fig_daily_views.update_layout(
            title='ì¼ìë³„ ì¡°íšŒìˆ˜ ì¶”ì´',
            xaxis_title='ë‚ ì§œ',
            yaxis_title='ì¡°íšŒìˆ˜',
            height=400
        )
        st.plotly_chart(fig_daily_views, use_container_width=True)
        
        # 2-2. ìš”ì¼ë³„ ë¶„ì„
        st.markdown("#### ğŸ“… ìš”ì¼ë³„ ë¶„ì„")
        df['weekday'] = df['date'].dt.day_name()
        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        weekday_korean = {
            'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
            'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼',
            'Sunday': 'ì¼ìš”ì¼'
        }
        
        weekday_stats = df.groupby('weekday').agg({
            'views': 'mean',
            'comments': 'mean'
        }).reindex(weekday_order).reset_index()
        weekday_stats['weekday'] = weekday_stats['weekday'].map(weekday_korean)
        
        col1, col2 = st.columns(2)
        
        # ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜
        with col1:
            fig_weekday_views = go.Figure()
            fig_weekday_views.add_trace(go.Bar(
                x=weekday_stats['weekday'],
                y=weekday_stats['views'],
                marker_color='#1976D2'
            ))
            fig_weekday_views.update_layout(
                title='ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜',
                xaxis_title='ìš”ì¼',
                yaxis_title='í‰ê·  ì¡°íšŒìˆ˜',
                height=400
            )
            st.plotly_chart(fig_weekday_views, use_container_width=True)
            
        # ìš”ì¼ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜
        with col2:
            fig_weekday_comments = go.Figure()
            fig_weekday_comments.add_trace(go.Bar(
                x=weekday_stats['weekday'],
                y=weekday_stats['comments'],
                marker_color='#FFA726'
            ))
            fig_weekday_comments.update_layout(
                title='ìš”ì¼ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜',
                xaxis_title='ìš”ì¼',
                yaxis_title='í‰ê·  ëŒ“ê¸€ìˆ˜',
                height=400
            )
            st.plotly_chart(fig_weekday_comments, use_container_width=True)
        
# 2-3. ì‹œê°„ëŒ€ë³„ ë¶„ì„
        st.markdown("#### ğŸ•’ ì‹œê°„ëŒ€ë³„ ë¶„ì„")
        df['hour'] = df['date'].dt.hour
        hourly_stats = df.groupby('hour').agg({
            'views': 'mean',
            'comments': 'mean'
        }).reset_index()
        
        # ëª¨ë“  ì‹œê°„ëŒ€(0-23)ê°€ í¬í•¨ë˜ë„ë¡ ë³´ì¥
        all_hours = pd.DataFrame({'hour': range(24)})
        hourly_stats = pd.merge(all_hours, hourly_stats, on='hour', how='left').fillna(0)
        
        col3, col4 = st.columns(2)
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜
        with col3:
            fig_hourly_views = go.Figure()
            fig_hourly_views.add_trace(go.Bar(
                x=hourly_stats['hour'],
                y=hourly_stats['views'],
                marker_color='#1976D2'
            ))
            fig_hourly_views.update_layout(
                title='ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜',
                xaxis_title='ì‹œê°„',
                yaxis_title='í‰ê·  ì¡°íšŒìˆ˜',
                height=400,
                xaxis=dict(
                    tickmode='array',
                    ticktext=[f'{i:02d}ì‹œ' for i in range(24)],
                    tickvals=list(range(24)),
                    range=[-0.5, 23.5]  # Xì¶• ë²”ìœ„ ì„¤ì •
                )
            )
            st.plotly_chart(fig_hourly_views, use_container_width=True)
            
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜
        with col4:
            fig_hourly_comments = go.Figure()
            fig_hourly_comments.add_trace(go.Bar(
                x=hourly_stats['hour'],
                y=hourly_stats['comments'],
                marker_color='#FFA726'
            ))
            fig_hourly_comments.update_layout(
                title='ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜',
                xaxis_title='ì‹œê°„',
                yaxis_title='í‰ê·  ëŒ“ê¸€ìˆ˜',
                height=400,
                xaxis=dict(
                    tickmode='array',
                    ticktext=[f'{i:02d}ì‹œ' for i in range(24)],
                    tickvals=list(range(24)),
                    range=[-0.5, 23.5]  # Xì¶• ë²”ìœ„ ì„¤ì •
                )
            )
            st.plotly_chart(fig_hourly_comments, use_container_width=True)
        
# 4. ìƒìœ„ ì˜ìƒ í…Œì´ë¸”
        st.subheader("ğŸ† ìƒìœ„ 20ê°œ ì˜ìƒ")
        df_display = df.nlargest(20, 'engagement_score')[
            ['title', 'views', 'likes', 'comments', 'engagement_score']
        ].reset_index(drop=True)
        df_display.index += 1
        st.table(df_display)
        
# 5. ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„
        st.subheader("ğŸ” ì œëª© í‚¤ì›Œë“œ ë¶„ì„")
        try:
            # í°íŠ¸ ê²½ë¡œ ì„¤ì •: í”„ë¡œì íŠ¸ í´ë”ì— í¬í•¨ëœ í°íŠ¸ ì‚¬ìš©
            current_dir = os.path.dirname(os.path.abspath(__file__))
            font_path = os.path.join(current_dir, 'NanumGothic.ttf')

            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            wordcloud = WordCloud(
                width=800, 
                height=400,
                background_color='white',
                font_path=font_path,  # í°íŠ¸ ê²½ë¡œ ì„¤ì •
                prefer_horizontal=0.7
            ).generate(' '.join(df['title']))

            # ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)

        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•œê¸€ í°íŠ¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# 6. Claude AI ë¶„ì„
        st.subheader("ğŸ¤– AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸")

        def format_analysis_response(text):
            """Claude API ì‘ë‹µì„ ê°€ë…ì„± ìˆê²Œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜"""
            formatted_text = ""
            lines = text.split('\n')
            
            for line in lines:
                line = line.strip()
                if not line:  # ë¹ˆ ì¤„ ì²˜ë¦¬
                    formatted_text += "\n"
                # ì£¼ìš” ì„¹ì…˜ í—¤ë” (1ï¸âƒ£, 2ï¸âƒ£, 3ï¸âƒ£, 4ï¸âƒ£)
                elif any(emoji in line for emoji in ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£']):
                    formatted_text += f"\n\n### {line}\n"
                # í•˜ìœ„ ì„¹ì…˜ í—¤ë” (â–¶ï¸)
                elif line.startswith('â–¶ï¸'):
                    formatted_text += f"\n#### {line}\n"
                # ì„¹ì…˜ ì œëª© (####ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
                elif line.startswith('####'):
                    formatted_text += f"\n{line}\n"
                # ì£¼ìš” í•­ëª© (â€¢ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
                elif line.startswith('â€¢'):
                    formatted_text += f"\n    * {line[1:].strip()}\n"
                # í•˜ìœ„ ìƒì„¸ ì„¤ëª… (-ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
                elif line.strip().startswith('-'):
                    formatted_text += f"\n        - {line[1:].strip()}\n"
                # ê¸°íƒ€ í…ìŠ¤íŠ¸
                else:
                    formatted_text += f"{line}\n"
            
            return formatted_text

        if self.claude_api_key:
            with st.spinner("AI ë¶„ì„ì„ ìˆ˜í–‰ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    client = Anthropic(api_key=self.claude_api_key)
                    
                    # DataFrameì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ê¸° ì „ì— ì „ì²˜ë¦¬
                    df_for_analysis = df.copy()
                    # Timestampë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    df_for_analysis['date'] = df_for_analysis['date'].astype(str)
                    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                    analysis_data = df_for_analysis[[
                        'title', 'views', 'likes', 'comments', 
                        'engagement_score', 'date'
                    ]].to_dict('records')
                    
                    # ì²« ë²ˆì§¸ ë¶„ì„: ì„±ê³¼ íŒ¨í„´ ë° ìµœì í™”
                    first_prompt = f"""ë‹¹ì‹ ì€ YouTube ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì²« ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

{json.dumps(analysis_data, ensure_ascii=False, indent=2)}

1ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì„±ê³¼ íŒ¨í„´
â–¶ï¸ ì¡°íšŒìˆ˜ ìƒìœ„ 25% ì˜ìƒ íŠ¹ì§•
 #### ì œëª© íŒ¨í„´ ë¶„ì„:
    â€¢ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
        - ì‚¬ìš© ë¹ˆë„ê°€ ë†’ì€ í•µì‹¬ í‚¤ì›Œë“œ
        - í‚¤ì›Œë“œ ì¡°í•© íŒ¨í„´
        - ì„±ê³¼ë³„ í‚¤ì›Œë“œ ë¶„í¬
    â€¢ ì œëª© êµ¬ì¡°ì˜ íŠ¹ì§•
        - íš¨ê³¼ì ì¸ ì œëª© ê¸¸ì´
        - ì£¼ìš” ë¬¸ì¥ êµ¬ì„± íŒ¨í„´
        - ì‹œì²­ì í˜¸ì‘ì´ ë†’ì€ êµ¬ì¡°
    â€¢ íš¨ê³¼ì ì¸ ì œëª© ì‚¬ë¡€
        - ëŒ€í‘œì  ì„±ê³µ ì‚¬ë¡€ ë¶„ì„
        - ê³µí†µëœ ì„±ê³µ ìš”ì¸
        - ì‹¤ì œ ì ìš© ë°©ì•ˆ

 #### ì¡°íšŒìˆ˜ì™€ ì°¸ì—¬ë„ ìƒê´€ê´€ê³„:
    â€¢ ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´
        - íŠ¹ì´ì  ë¶„ì„
        - ì„±ê³µ ìš”ì¸ ë„ì¶œ
        - ì ìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸

 #### ì„±ê³µì ì¸ ì˜ìƒì˜ ê³µí†µì :
    â€¢ ì½˜í…ì¸  êµ¬ì„± íŠ¹ì§•
        - íš¨ê³¼ì ì¸ êµ¬ì„± ìš”ì†Œ
        - ì‹œì²­ì ë°˜ì‘ì´ ì¢‹ì€ í¬ë§·
        - í•µì‹¬ ì„±ê³µ ìš”ì¸
    â€¢ ì‹œì²­ì ë°˜ì‘ íŒ¨í„´
        - ê¸ì •ì  ë°˜ì‘ ìš”ì¸
        - ì°¸ì—¬ë„ ì¦ê°€ ìš”ì†Œ
        - ì‹œì²­ì í–‰ë™ ë¶„ì„
    â€¢ ì°¨ë³„í™” ìš”ì†Œ
        - ë…íŠ¹í•œ ê°•ì  ë¶„ì„
        - ê²½ìŸë ¥ ìˆëŠ” íŠ¹ì§•
        - ë²¤ì¹˜ë§ˆí‚¹ í¬ì¸íŠ¸

2ï¸âƒ£ ìµœì í™” ì¸ì‚¬ì´íŠ¸
â–¶ï¸ ì œëª© ìµœì í™” ì „ëµ
 #### íš¨ê³¼ì ì¸ ì œëª© êµ¬ì„± ìš”ì†Œ:
    â€¢ í•µì‹¬ í‚¤ì›Œë“œ
        - í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ
        - íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ ìˆœì„œ
        - í‚¤ì›Œë“œ ì¡°í•© ì „ëµ
    â€¢ êµ¬ì¡°ì  íŠ¹ì§•
        - ìµœì ì˜ ì œëª© êµ¬ì¡°
        - íš¨ê³¼ì ì¸ ë¬¸ì¥ íŒ¨í„´
        - ì‹œì²­ì ì£¼ëª©ë„ ë†’ì€ í˜•ì‹
    â€¢ ê¸¸ì´ ë° í˜•ì‹
        - ìµœì ì˜ ì œëª© ê¸¸ì´
        - ì¶”ì²œ í¬ë§· ê°€ì´ë“œ
        - ì‹¤ìš©ì  ì ìš© ë°©ì•ˆ

 #### ì‹œì²­ì ê´€ì‹¬ì„ ë„ëŠ” í‚¤ì›Œë“œ:
    â€¢ ìƒìœ„ ì„±ê³¼ í‚¤ì›Œë“œ
        - ì¡°íšŒìˆ˜ ì—°ê´€ í‚¤ì›Œë“œ
        - ì°¸ì—¬ë„ ì—°ê´€ í‚¤ì›Œë“œ
        - ì„±ê³¼ë³„ í‚¤ì›Œë“œ ë¶„ì„
    â€¢ ì‹œì²­ì ë°˜ì‘ì´ ì¢‹ì€ í‘œí˜„
        - íš¨ê³¼ì ì¸ ë¬¸êµ¬ íŒ¨í„´
        - ê°ì • ë°˜ì‘ ìœ ë„ ìš”ì†Œ
        - ì°¸ì—¬ ìœ ë„ í‘œí˜„
    â€¢ íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„
        - ì‹œê¸°ë³„ ìœ íš¨ í‚¤ì›Œë“œ
        - í™œìš© ì „ëµ ì œì•ˆ

 #### ê°œì„  ì œì•ˆ:
    â€¢ êµ¬ì²´ì  ìµœì í™” ë°©ì•ˆ
        - ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ ì 
        - ë‹¨ê³„ë³„ ìµœì í™” ì „ëµ
        - ì‹¤í–‰ ìš°ì„ ìˆœìœ„
    â€¢ í…ŒìŠ¤íŠ¸ ì¶”ì²œ ì‚¬í•­
        - A/B í…ŒìŠ¤íŠ¸ í•­ëª©
        - ì„±ê³¼ ì¸¡ì • ë°©ë²•
        - ê°œì„  í”„ë¡œì„¸ìŠ¤
    â€¢ ì£¼ì˜í•´ì•¼ í•  ì 
        - ìœ„í—˜ ìš”ì†Œ ë¶„ì„
        - íšŒí”¼í•´ì•¼ í•  íŒ¨í„´
        - í’ˆì§ˆ ê´€ë¦¬ í¬ì¸íŠ¸

ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.

ê° í•­ëª©ì€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

                    first_response = client.messages.create(
                        model="claude-3-haiku-20240307",
                        max_tokens=3000,
                        temperature=0.3,
                        messages=[{"role": "user", "content": first_prompt}]
                    )

                    # ë‘ ë²ˆì§¸ ë¶„ì„: ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ë° ì œì‘ ê°€ì´ë“œ
                    second_prompt = f"""ì´ì–´ì„œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‘ ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

{json.dumps(analysis_data, ensure_ascii=False, indent=2)}

3ï¸âƒ£ ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
â–¶ï¸ ì—…ë¡œë“œ ì „ëµ
 #### ìµœì ì˜ ì—…ë¡œë“œ ì‹œê°„ëŒ€:
    â€¢ ì¡°íšŒìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì‹œê°„ëŒ€
        - ì‹œê°„ëŒ€ë³„ ì¡°íšŒìˆ˜ ë¶„ì„
        - ìµœì  ì‹œê°„ëŒ€ ë„ì¶œ
        - ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ì°¨ì´
    â€¢ ì°¸ì—¬ë„ê°€ ê°€ì¥ ë†’ì€ ì‹œê°„ëŒ€
        - ëŒ“ê¸€/ì¢‹ì•„ìš” ì°¸ì—¬ìœ¨ ë¶„ì„
        - ì‹œì²­ì í™œë™ ì‹œê°„ëŒ€
        - íš¨ê³¼ì ì¸ ì—…ë¡œë“œ íƒ€ì´ë°
    â€¢ ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ì°¨ì´
        - ì£¼ìš” ì„±ê³¼ ì§€í‘œ ë¹„êµ
        - ì‹œê°„ëŒ€ë³„ íŠ¹ì„± ë¶„ì„
        - ì „ëµì  ì‹œì‚¬ì 

 #### ì‹œì²­ì ì°¸ì—¬ê°€ ë†’ì€ ê¸°ê°„:
    â€¢ ìš”ì¼ë³„ ì„±ê³¼ ë¶„ì„
        - ìš”ì¼ë³„ ì¡°íšŒìˆ˜ íŒ¨í„´
        - ì°¸ì—¬ë„ ë³€í™” ì¶”ì´
        - ìµœì  ì—…ë¡œë“œ ìš”ì¼
    â€¢ ì›”ë³„/ê³„ì ˆë³„ íŠ¸ë Œë“œ
        - ì›”ë³„ ì„±ê³¼ ë¹„êµ
        - ê³„ì ˆì  íŠ¹ì„± ë¶„ì„
        - ì¥ê¸° íŠ¸ë Œë“œ íŒ¨í„´
    â€¢ íŠ¹ì • ê¸°ê°„ ì„±ê³¼ íŒ¨í„´
        - ì£¼ìš” ì„±ê³¼ êµ¬ê°„ ë¶„ì„
        - ì„±ê³µ ìš”ì¸ ë„ì¶œ
        - ì „ëµì  í™œìš© ë°©ì•ˆ

 #### ì‹œì¦Œë³„ íŠ¸ë Œë“œ:
    â€¢ ê³„ì ˆë³„ ì„±ê³¼ ë¹„êµ
        - ê³„ì ˆë³„ ì„±ê³¼ ì°¨ì´
        - ì‹œì¦Œë³„ íŠ¹ì„± ë¶„ì„
        - ì‹œì¦Œ ë§ì¶¤ ì „ëµ
    â€¢ íŠ¹ë³„í•œ ì‹œê¸°/ì´ë²¤íŠ¸ ì˜í–¥
        - ì£¼ìš” ì´ë²¤íŠ¸ ì˜í–¥ë„
        - íŠ¹ë³„ ì‹œê¸° ì „ëµ
        - ì´ë²¤íŠ¸ í™œìš© ë°©ì•ˆ
    â€¢ ì¥ê¸°ì  íŠ¸ë Œë“œ íŒ¨í„´
        - ì—°ê°„ íŠ¸ë Œë“œ ë¶„ì„
        - ì„±ì¥ íŒ¨í„´ ë„ì¶œ
        - ì¥ê¸° ì „ëµ ìˆ˜ë¦½

4ï¸âƒ£ ì½˜í…ì¸  ì œì‘ ê°€ì´ë“œ
â–¶ï¸ í¬ë§· ìµœì í™”
 #### ì„±ê³¼ê°€ ì¢‹ì€ ì½˜í…ì¸  ìœ í˜•:
    â€¢ ìƒìœ„ ì„±ê³¼ ì½˜í…ì¸  ë¶„ì„
        - í•µì‹¬ ì„±ê³µ ìš”ì¸
        - í¬ë§·ë³„ ì„±ê³¼ ë¹„êµ
        - ìµœì í™” í¬ì¸íŠ¸
    â€¢ ê³µí†µëœ êµ¬ì„± ìš”ì†Œ
        - íš¨ê³¼ì ì¸ êµ¬ì„± ë°©ì‹
        - í•µì‹¬ êµ¬ì„± ìš”ì†Œ
        - ì‹œì²­ì ì„ í˜¸ íŒ¨í„´
    â€¢ ì°¨ë³„í™” í¬ì¸íŠ¸
        - ë…íŠ¹í•œ ê°•ì  ë¶„ì„
        - ê²½ìŸë ¥ ìš”ì†Œ
        - ì°¨ë³„í™” ì „ëµ

 #### ì‹œì²­ì ì°¸ì—¬ë„ë¥¼ ë†’ì´ëŠ” ìš”ì†Œ:
    â€¢ íš¨ê³¼ì ì¸ ì°¸ì—¬ ìœ ë„ ë°©ë²•
        - ëŒ“ê¸€ ìœ ë„ ì „ëµ
        - ì‹œì²­ì í˜¸ì‘ ìš”ì†Œ
        - ìƒí˜¸ì‘ìš© ìµœì í™”
    â€¢ ëŒ“ê¸€ í™œì„±í™” ì „ëµ
        - íš¨ê³¼ì ì¸ í˜¸ì‘ ìœ ë„
        - ëŒ“ê¸€ ê´€ë¦¬ ë°©ì•ˆ
        - ì»¤ë®¤ë‹ˆí‹° í™œì„±í™”
    â€¢ ì‹œì²­ì ìƒí˜¸ì‘ìš© íŒ¨í„´
        - ì°¸ì—¬ íŒ¨í„´ ë¶„ì„
        - íš¨ê³¼ì ì¸ ì†Œí†µ ë°©ì‹
        - ê´€ê³„ êµ¬ì¶• ì „ëµ

â–¶ï¸ ì‹¤ì „ ì œì‘ ì „ëµ
 #### êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ:
    â€¢ ì½˜í…ì¸  ê¸°íš ê°€ì´ë“œ
        - ê¸°íš í”„ë¡œì„¸ìŠ¤
        - í•µì‹¬ ê³ ë ¤ì‚¬í•­
        - í’ˆì§ˆ ê´€ë¦¬ ë°©ì•ˆ
    â€¢ ì œì‘ í”„ë¡œì„¸ìŠ¤ ìµœì í™”
        - íš¨ìœ¨ì  ì œì‘ ê³¼ì •
        - ë¦¬ì†ŒìŠ¤ ìµœì í™”
        - í’ˆì§ˆ í–¥ìƒ ë°©ì•ˆ
    â€¢ í’ˆì§ˆ í–¥ìƒ ì „ëµ
        - í•µì‹¬ í’ˆì§ˆ ìš”ì†Œ
        - ê°œì„  í¬ì¸íŠ¸
        - ì‹¤í–‰ ê°€ì´ë“œë¼ì¸

 #### ê°œì„ ì  ì œì•ˆ:
    â€¢ ë‹¨ê¸° ê°œì„  ì‚¬í•­
        - ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ ì 
        - ìš°ì„ ìˆœìœ„ ì„¤ì •
        - ì‹¤í–‰ ê³„íš
    â€¢ ì¥ê¸° ë°œì „ ë°©í–¥
        - ì¥ê¸° ëª©í‘œ ì„¤ì •
        - ë‹¨ê³„ë³„ ë°œì „ ê³„íš
        - ì„±ì¥ ì „ëµ
    â€¢ ê²½ìŸë ¥ ê°•í™” í¬ì¸íŠ¸
        - í•µì‹¬ ê²½ìŸë ¥ ìš”ì†Œ
        - ì°¨ë³„í™” ì „ëµ
        - ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ ë°©ì•ˆ

ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.

ê° í•­ëª©ì€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

                    second_response = client.messages.create(
                        model="claude-3-haiku-20240307",
                        max_tokens=3000,
                        temperature=0.3,
                        messages=[{"role": "user", "content": second_prompt}]
                    )

# ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    if hasattr(first_response.content[0], 'text'):
                        # ìƒˆë¡œìš´ API ì‘ë‹µ í˜•ì‹
                        first_analysis = first_response.content[0].text
                        second_analysis = second_response.content[0].text
                    else:
                        # ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹
                        first_analysis = first_response.content
                        second_analysis = second_response.content

                    st.markdown(format_analysis_response(first_analysis))
                    st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
                    st.markdown(format_analysis_response(second_analysis))

                except Exception as e:
                    st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.write("ìƒì„¸ ì˜¤ë¥˜:", e)  # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì˜¤ë¥˜ í‘œì‹œ
        else:
            st.warning("Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
    def run_analysis(self):
        try:
            if not self.youtube_api_key:
                st.error("YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return
                
            st.info("YouTube ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...")
            youtube = build("youtube", "v3", developerKey=self.youtube_api_key)
            videos_data = self.collect_videos_data(youtube)
            
            if not videos_data:
                st.error("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            df = pd.DataFrame(videos_data)
            self.create_dashboard(df)
            
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    def run(self):
        if not self.youtube_api_key:
            st.error("YouTube API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        if st.sidebar.button("ë¶„ì„ ì‹œì‘", use_container_width=True):
            if self.keyword:
                self.run_analysis()
            else:
                st.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    app = YouTubeAnalytics()
    app.run()
