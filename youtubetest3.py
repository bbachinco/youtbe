import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from googleapiclient.discovery import build
from datetime import datetime, timedelta
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from anthropic import Anthropic
import json
import os
from dotenv import load_dotenv
import time  # time ëª¨ë“ˆ ì¶”ê°€

class YouTubeAnalytics:
    def __init__(self):
        # API í• ë‹¹ëŸ‰ ê´€ë¦¬ì™€ ìºì‹œ ì´ˆê¸°í™” ì¶”ê°€
        self.quota_limit = 10000  # ì¼ì¼ í• ë‹¹ëŸ‰
        self.quota_used = 0  # ì‚¬ìš©ëœ í• ë‹¹ëŸ‰ ì¶”ì 
        self.cache = {}  # ìºì‹œ ì´ˆê¸°í™”
        
        self.load_api_keys()
        st.set_page_config(page_title="YouTube ì½˜í…ì¸  ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
        
        # Custom CSS ì¶”ê°€
        st.markdown("""
            <style>
                h3 {
                    margin-top: 40px;
                    margin-bottom: 20px;
                    color: #1e88e5;
                    font-size: 1.5em;
                }
                h4 {
                    margin-top: 25px;
                    margin-bottom: 15px;
                    color: #2196f3;
                    font-size: 1.2em;
                }
                ul {
                    margin-left: 20px;
                    margin-bottom: 15px;
                }
                li {
                    margin-bottom: 8px;
                }
            </style>
        """, unsafe_allow_html=True)
        
        self.setup_sidebar()

    def check_quota(self, cost):
        """API í˜¸ì¶œ ì „ í• ë‹¹ëŸ‰ í™•ì¸"""
        if self.quota_used + cost > self.quota_limit:
            raise Exception("ì¼ì¼ API í• ë‹¹ëŸ‰ ì´ˆê³¼")
        self.quota_used += cost
        return True

    def load_api_keys(self):
        # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
        load_dotenv()
        self.youtube_api_key = os.getenv('YOUTUBE_API_KEY')
        self.claude_api_key = os.getenv('CLAUDE_API_KEY')
        
        # API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì—†ëŠ” ê²½ìš° Streamlit secretsì—ì„œ ì‹œë„
        if not self.youtube_api_key:
            try:
                self.youtube_api_key = st.secrets["YOUTUBE_API_KEY"]
            except:
                self.youtube_api_key = None
                
        if not self.claude_api_key:
            try:
                self.claude_api_key = st.secrets["CLAUDE_API_KEY"]
            except:
                self.claude_api_key = None

    def setup_sidebar(self):
        with st.sidebar:
            st.title("âš™ï¸ ì„¤ì •")
            
            # API í‚¤ ì…ë ¥ í•„ë“œ (ì´ë¯¸ ë¡œë“œëœ í‚¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ í‘œì‹œ)
            if not self.youtube_api_key:
                self.youtube_api_key = st.text_input("YouTube API Key", type="password")
            if not self.claude_api_key:
                self.claude_api_key = st.text_input("Claude API Key", type="password")
            
            self.keyword = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œ")
            self.max_results = st.slider("ê²€ìƒ‰í•  ìµœëŒ€ ì˜ìƒ ìˆ˜", 10, 100, 50)
            self.date_range = st.slider("ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 24, 12)
            
    def collect_videos_data(self, youtube):
        cache_key = f"{self.keyword}_{self.date_range}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            return self.cache[cache_key]
            
        try:
            date_limit = (datetime.now() - timedelta(days=30 * self.date_range)).isoformat() + "Z"
            
            # search().list í˜¸ì¶œ ì „ í• ë‹¹ëŸ‰ í™•ì¸ (100 units)
            self.check_quota(100)
            
            # ì²« ë²ˆì§¸ API í˜¸ì¶œ: ê²€ìƒ‰ ë° snippet ì •ë³´ í•¨ê»˜ ê°€ì ¸ì˜¤ê¸°
            search_response = youtube.search().list(
                q=self.keyword,
                type="video",
                part="id,snippet",  # snippet í¬í•¨í•˜ì—¬ API í˜¸ì¶œ ìµœì†Œí™”
                maxResults=min(50, self.max_results),
                publishedAfter=date_limit
            ).execute()
            
            videos = []
            video_ids = []
            
            for item in search_response.get('items', []):
                video_ids.append(item['id']['videoId'])
                videos.append({
                    'id': item['id']['videoId'],
                    'title': item['snippet']['title'],
                    'publishedAt': item['snippet']['publishedAt'],
                    'description': item['snippet']['description']
                })
            
            if video_ids:
                # videos().list í˜¸ì¶œ ì „ í• ë‹¹ëŸ‰ í™•ì¸ (1 unit per video)
                self.check_quota(len(video_ids))
                
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                time.sleep(0.5)
                
                # ë‘ ë²ˆì§¸ API í˜¸ì¶œ: í†µê³„ ì •ë³´
                videos_response = youtube.videos().list(
                    part='statistics,contentDetails',
                    id=','.join(video_ids)
                ).execute()
                
                # videos().list í˜¸ì¶œ í›„ì— ëŒ“ê¸€ ìˆ˜ì§‘ ì¶”ê°€
                for video in videos:
                    try:
                        # ëŒ“ê¸€ ìˆ˜ì§‘ ì „ í• ë‹¹ëŸ‰ í™•ì¸
                        self.check_quota(1)
                        comments_response = youtube.commentThreads().list(
                            part="snippet",
                            videoId=video['id'],
                            maxResults=100
                        ).execute()
                        
                        video['comments_data'] = [
                            item['snippet']['topLevelComment']['snippet']['textDisplay']
                            for item in comments_response.get('items', [])
                        ]
                    except Exception as e:
                        video['comments_data'] = []
                
                for video_data in videos_response.get('items', []):
                    video_id = video_data['id']
                    for video in videos:
                        if video['id'] == video_id:
                            stats = video_data['statistics']
                            video.update({
                                'views': int(stats.get('viewCount', 0)),
                                'likes': int(stats.get('likeCount', 0)),
                                'comments': int(stats.get('commentCount', 0)),
                                'duration': video_data['contentDetails']['duration']
                            })
            
            # 1000íšŒ ì´ìƒ ì¡°íšŒëœ ì˜ìƒ í•„í„°ë§
            filtered_videos = [
                video for video in videos 
                if video.get('views', 0) >= 1000
            ]
            
            processed_videos = self.calculate_engagement_scores(filtered_videos)
            
            # ê²°ê³¼ ìºì‹±
            self.cache[cache_key] = processed_videos
            
            return processed_videos
            
        except Exception as e:
            st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []

    def calculate_engagement_scores(self, videos):
        if not videos:
            return []
            
        # ëŒ“ê¸€ ë¹„ìœ¨ ë¶„ì„ì„ í†µí•œ ì´ìƒì¹˜ ì œê±°
        comment_ratios = [
            (video['comments'] / video['views'] * 100) 
            for video in videos if video['views'] > 0
        ]
        avg_ratio = np.mean(comment_ratios)
        std_ratio = np.std(comment_ratios)
        threshold = avg_ratio + (2 * std_ratio)
        
        one_week_ago = datetime.now() - timedelta(days=7)
        
        processed_videos = []
        for video in videos:
            try:
                views = video['views']
                likes = video['likes']
                comments = video['comments']
                publish_date = datetime.strptime(
                    video['publishedAt'], 
                    '%Y-%m-%dT%H:%M:%SZ'
                )
                
                comment_ratio = (comments / views * 100) if views > 0 else 0
                
                # ë¹„ì •ìƒì ì¸ ëŒ“ê¸€ ë¹„ìœ¨ ì œì™¸
                if comment_ratio > threshold:
                    continue
                    
                like_ratio = (likes / views * 100) if views > 0 else 0
                recency_score = 1.2 if publish_date > one_week_ago else 1.0
                
                engagement_score = (
                    like_ratio + 
                    (comment_ratio * 3)  # ëŒ“ê¸€ ê°€ì¤‘ì¹˜ 3ë°°
                ) * recency_score
                
                video['engagement_score'] = engagement_score
                video['like_ratio'] = like_ratio
                video['comment_ratio'] = comment_ratio
                video['is_recent'] = publish_date > one_week_ago
                
                processed_videos.append(video)
                
            except Exception as e:
                st.warning(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ì¸ê²Œì´ì§€ë¨¼íŠ¸ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        return sorted(
            processed_videos, 
            key=lambda x: x['engagement_score'], 
            reverse=True
        )[:20]  # ìƒìœ„ 20ê°œë§Œ ë°˜í™˜
        
    def create_dashboard(self, df):
        st.title(f"ğŸ“Š YouTube í‚¤ì›Œë“œ ë¶„ì„: {self.keyword}")
        
        # 1. ì£¼ìš” ì§€í‘œ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ë¶„ì„ ì˜ìƒ", f"{len(df):,}ê°œ")
        with col2:
            st.metric("ì´ ì¡°íšŒìˆ˜", f"{df['views'].sum():,}íšŒ")
        with col3:
            st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{int(df['likes'].mean()):,}ê°œ")
        with col4:
            st.metric("í‰ê·  ëŒ“ê¸€", f"{int(df['comments'].mean()):,}ê°œ")
        
        # 2. ì‹œê³„ì—´ ë¶„ì„
        st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ë¶„ì„")
        df['date'] = pd.to_datetime(df['publishedAt'])
              
        # 2-2. ìš”ì¼ë³„ ë¶„ì„
        st.markdown("#### ğŸ“… ìš”ì¼ë³„ ë¶„ì„")
        df['weekday'] = df['date'].dt.day_name()
        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        weekday_korean = {
            'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
            'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼',
            'Sunday': 'ì¼ìš”ì¼'
        }
        
        weekday_stats = df.groupby('weekday').agg({
            'views': 'mean',
            'comments': 'mean'
        }).reindex(weekday_order).reset_index()
        weekday_stats['weekday'] = weekday_stats['weekday'].map(weekday_korean)
        
        col1, col2 = st.columns(2)
        
        # ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜
        with col1:
            fig_weekday_views = go.Figure()
            fig_weekday_views.add_trace(go.Bar(
                x=weekday_stats['weekday'],
                y=weekday_stats['views'],
                marker_color='#1976D2'
            ))
            fig_weekday_views.update_layout(
                title='ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜',
                xaxis_title='ìš”ì¼',
                yaxis_title='í‰ê·  ì¡°íšŒìˆ˜',
                height=400
            )
            st.plotly_chart(fig_weekday_views, use_container_width=True)
            
        # ìš”ì¼ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜
        with col2:
            fig_weekday_comments = go.Figure()
            fig_weekday_comments.add_trace(go.Bar(
                x=weekday_stats['weekday'],
                y=weekday_stats['comments'],
                marker_color='#FFA726'
            ))
            fig_weekday_comments.update_layout(
                title='ìš”ì¼ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜',
                xaxis_title='ìš”ì¼',
                yaxis_title='í‰ê·  ëŒ“ê¸€ìˆ˜',
                height=400
            )
            st.plotly_chart(fig_weekday_comments, use_container_width=True)
        
        # 2-3. ì‹œê°„ëŒ€ë³„ ë¶„ì„
        st.markdown("#### ğŸ•’ ì‹œê°„ëŒ€ë³„ ë¶„ì„")
        df['hour'] = df['date'].dt.hour
        hourly_stats = df.groupby('hour').agg({
            'views': 'mean',
            'comments': 'mean'
        }).reset_index()
        
        # ëª¨ë“  ì‹œê°„ëŒ€(0-23)ê°€ í¬í•¨ë˜ë„ë¡ ë³´ì¥
        all_hours = pd.DataFrame({'hour': range(24)})
        hourly_stats = pd.merge(all_hours, hourly_stats, on='hour', how='left').fillna(0)
        
        col3, col4 = st.columns(2)
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜
        with col3:
            fig_hourly_views = go.Figure()
            fig_hourly_views.add_trace(go.Bar(
                x=hourly_stats['hour'],
                y=hourly_stats['views'],
                marker_color='#1976D2'
            ))
            fig_hourly_views.update_layout(
                title='ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜',
                xaxis_title='ì‹œê°„',
                yaxis_title='í‰ê·  ì¡°íšŒìˆ˜',
                height=400,
                xaxis=dict(
                    tickmode='array',
                    ticktext=[f'{i:02d}ì‹œ' for i in range(24)],
                    tickvals=list(range(24)),
                    range=[-0.5, 23.5]  # Xì¶• ë²”ìœ„ ì„¤ì •
                )
            )
            st.plotly_chart(fig_hourly_views, use_container_width=True)
            
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜
        with col4:
            fig_hourly_comments = go.Figure()
            fig_hourly_comments.add_trace(go.Bar(
                x=hourly_stats['hour'],
                y=hourly_stats['comments'],
                marker_color='#FFA726'
            ))
            fig_hourly_comments.update_layout(
                title='ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ“ê¸€ìˆ˜',
                xaxis_title='ì‹œê°„',
                yaxis_title='í‰ê·  ëŒ“ê¸€ìˆ˜',
                height=400,
                xaxis=dict(
                    tickmode='array',
                    ticktext=[f'{i:02d}ì‹œ' for i in range(24)],
                    tickvals=list(range(24)),
                    range=[-0.5, 23.5]  # Xì¶• ë²”ìœ„ ì„¤ì •
                )
            )
            st.plotly_chart(fig_hourly_comments, use_container_width=True)
        
        # 4. ìƒìœ„ ì˜ìƒ í…Œì´ë¸”
        st.subheader("ğŸ† ìƒìœ„ 20ê°œ ì˜ìƒ")
        df_display = df.nlargest(20, 'engagement_score')[
            ['title', 'views', 'likes', 'comments', 'engagement_score']
        ].reset_index(drop=True)
        df_display.index += 1
        st.table(df_display)
        
        # 5. ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„
        st.subheader("ğŸ” ì œëª© í‚¤ì›Œë“œ ë¶„ì„")
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            font_path = os.path.join(current_dir, 'Pretendard-Bold.ttf')

            wordcloud = WordCloud(
                width=800, 
                height=400,
                background_color='white',
                font_path=font_path,
                prefer_horizontal=0.7
            ).generate(' '.join(df['title']))

            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)

        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•œê¸€ í°íŠ¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    def run_analysis(self):
        try:
            if not self.youtube_api_key:
                st.error("YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return
                
            st.info("YouTube ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...")
            youtube = build("youtube", "v3", developerKey=self.youtube_api_key)
            
            # API í• ë‹¹ëŸ‰ ì´ˆê³¼ í™•ì¸
            try:
                videos_data = self.collect_videos_data(youtube)
            except Exception as e:
                if "ì¼ì¼ API í• ë‹¹ëŸ‰ ì´ˆê³¼" in str(e):
                    st.error("YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return
                raise e
            
            if not videos_data:
                st.error("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            df = pd.DataFrame(videos_data)
            self.create_dashboard(df)
            
            # Claude AI ë¶„ì„ ì‹¤í–‰
            if self.claude_api_key:
                self.run_ai_analysis(df)
            
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


    def format_analysis_response(self, text):
        """Claude API ì‘ë‹µì„ ê°€ë…ì„± ìˆê²Œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜"""
        formatted_text = ""
        lines = text.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:  # ë¹ˆ ì¤„ ì²˜ë¦¬
                formatted_text += "\n"
            elif any(emoji in line for emoji in ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£']):
                formatted_text += f"\n\n### {line}\n"
            elif line.startswith('â–¶ï¸'):
                formatted_text += f"\n#### {line}\n"
            elif line.startswith('####'):
                formatted_text += f"\n{line}\n"
            elif line.startswith('â€¢'):
                formatted_text += f"\n    * {line[1:].strip()}\n"
            elif line.strip().startswith('-'):
                formatted_text += f"\n        - {line[1:].strip()}\n"
            else:
                formatted_text += f"{line}\n"
        
        return formatted_text

    def run_ai_analysis(self, df):
        st.subheader("ğŸ¤– AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
        
        if not self.claude_api_key:
            st.warning("Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
            
        with st.spinner("AI ë¶„ì„ì„ ìˆ˜í–‰ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                client = Anthropic(api_key=self.claude_api_key)
                
                # DataFrameì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ê¸° ì „ì— ì „ì²˜ë¦¬
                df_for_analysis = df.copy()
                df_for_analysis['date'] = df_for_analysis['date'].astype(str)
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                analysis_data = df_for_analysis[[
                    'title', 'views', 'likes', 'comments', 
                    'engagement_score', 'date'
                ]].to_dict('records')
                
                # ê¸°ì¡´ì˜ ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆˆ í”„ë¡¬í”„íŠ¸ ë°©ì‹ ìœ ì§€
                first_response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{
                        "role": "user", 
                        "content": self.first_prompt(analysis_data)
                    }]
                )

                time.sleep(4)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ

                second_response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{
                        "role": "user", 
                        "content": self.second_prompt(analysis_data)
                    }]
                )

                # ê²°ê³¼ í‘œì‹œ
                if hasattr(first_response.content[0], 'text'):
                    # ìƒˆë¡œìš´ API ì‘ë‹µ í˜•ì‹
                    first_analysis = first_response.content[0].text
                    second_analysis = second_response.content[0].text
                else:
                    # ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹
                    first_analysis = first_response.content
                    second_analysis = second_response.content

                st.markdown(self.format_analysis_response(first_analysis))
                st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
                st.markdown(self.format_analysis_response(second_analysis))
                
            except Exception as e:
                st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.write("ìƒì„¸ ì˜¤ë¥˜:", e)

    # í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ ì¶”ê°€
    def first_prompt(self, analysis_data):
        return f"""ë‹¹ì‹ ì€ YouTube ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì²« ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

    {json.dumps(analysis_data, ensure_ascii=False, indent=2)}

    1ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì„±ê³¼ íŒ¨í„´
â–¶ï¸ ì¡°íšŒìˆ˜ ìƒìœ„ 25% ì˜ìƒ íŠ¹ì§•
 #### ì œëª© íŒ¨í„´ ë¶„ì„:
    â€¢ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
        - ì‚¬ìš© ë¹ˆë„ê°€ ë†’ì€ í•µì‹¬ í‚¤ì›Œë“œ
        - í‚¤ì›Œë“œ ì¡°í•© íŒ¨í„´
        - ì„±ê³¼ë³„ í‚¤ì›Œë“œ ë¶„í¬
    â€¢ ì œëª© êµ¬ì¡°ì˜ íŠ¹ì§•
        - íš¨ê³¼ì ì¸ ì œëª© ê¸¸ì´
        - ì£¼ìš” ë¬¸ì¥ êµ¬ì„± íŒ¨í„´
        - ì‹œì²­ì í˜¸ì‘ì´ ë†’ì€ êµ¬ì¡°
    â€¢ íš¨ê³¼ì ì¸ ì œëª© ì‚¬ë¡€
        - ëŒ€í‘œì  ì„±ê³µ ì‚¬ë¡€ ë¶„ì„
        - ê³µí†µëœ ì„±ê³µ ìš”ì¸
        - ì‹¤ì œ ì ìš© ë°©ì•ˆ

 #### ì„±ê³µì ì¸ ì˜ìƒì˜ ê³µí†µì :
    â€¢ ì½˜í…ì¸  êµ¬ì„± íŠ¹ì§•
        - íš¨ê³¼ì ì¸ êµ¬ì„± ìš”ì†Œ
        - ì‹œì²­ì ë°˜ì‘ì´ ì¢‹ì€ í¬ë§·
        - í•µì‹¬ ì„±ê³µ ìš”ì¸
    â€¢ ì‹œì²­ì ë°˜ì‘ íŒ¨í„´
        - ê¸ì •ì  ë°˜ì‘ ìš”ì¸
        - ì°¸ì—¬ë„ ì¦ê°€ ìš”ì†Œ
        - ì‹œì²­ì í–‰ë™ ë¶„ì„
    â€¢ ì°¨ë³„í™” ìš”ì†Œ
        - ë…íŠ¹í•œ ê°•ì  ë¶„ì„
        - ê²½ìŸë ¥ ìˆëŠ” íŠ¹ì§•
        - ë²¤ì¹˜ë§ˆí‚¹ í¬ì¸íŠ¸

2ï¸âƒ£ ìµœì í™” ì¸ì‚¬ì´íŠ¸
â–¶ï¸ ì œëª© ìµœì í™” ì „ëµ
 #### íš¨ê³¼ì ì¸ ì œëª© êµ¬ì„± ìš”ì†Œ:
    â€¢ í•µì‹¬ í‚¤ì›Œë“œ
        - í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ
        - íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ ìˆœì„œ
        - í‚¤ì›Œë“œ ì¡°í•© ì „ëµ
    â€¢ êµ¬ì¡°ì  íŠ¹ì§•
        - ìµœì ì˜ ì œëª© êµ¬ì¡°
        - íš¨ê³¼ì ì¸ ë¬¸ì¥ íŒ¨í„´
        - ì‹œì²­ì ì£¼ëª©ë„ ë†’ì€ í˜•ì‹
    â€¢ ê¸¸ì´ ë° í˜•ì‹
        - ìµœì ì˜ ì œëª© ê¸¸ì´
        - ì¶”ì²œ í¬ë§· ê°€ì´ë“œ
        - ì‹¤ìš©ì  ì ìš© ë°©ì•ˆ

 #### ì‹œì²­ì ê´€ì‹¬ì„ ë„ëŠ” í‚¤ì›Œë“œ:
    â€¢ ìƒìœ„ ì„±ê³¼ í‚¤ì›Œë“œ
        - ì¡°íšŒìˆ˜ ì—°ê´€ í‚¤ì›Œë“œ
        - ì°¸ì—¬ë„ ì—°ê´€ í‚¤ì›Œë“œ
        - ì„±ê³¼ë³„ í‚¤ì›Œë“œ ë¶„ì„
    â€¢ ì‹œì²­ì ë°˜ì‘ì´ ì¢‹ì€ í‘œí˜„
        - íš¨ê³¼ì ì¸ ë¬¸êµ¬ íŒ¨í„´
        - ê°ì • ë°˜ì‘ ìœ ë„ ìš”ì†Œ
        - ì°¸ì—¬ ìœ ë„ í‘œí˜„
    â€¢ íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„
        - ì‹œê¸°ë³„ ìœ íš¨ í‚¤ì›Œë“œ
        - í™œìš© ì „ëµ ì œì•ˆ


ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
4. 'ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„', 'ì‹œì²­ì ê´€ì‹¬ì„ ë„ëŠ” í‚¤ì›Œë“œ'ì—ì„œëŠ” ë¶„ì„í•  í‚¤ì›Œë“œëŠ” ì œì™¸í•˜ê³  ê·¸ì™¸ í‚¤ì›Œë“œë¥¼ ìœ„ì£¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ê° í•­ëª©ë³„ ë¶„ì„ ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ì™œ ì´ëŸ° ê°’ì´ ë‚˜ì™”ì„ì§€ ìš”ì¸ì— ëŒ€í•œ ê°€ì„¤ì„ ë‚´ì„¸ì›Œë³´ì„¸ìš”.

ê° í•­ëª©ì€ 20ê°œì˜ ì˜ìƒë“¤ì˜ ì˜ˆì‹œì™€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•´ì„œ ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    def second_prompt(self, analysis_data):
        return f"""ì´ì–´ì„œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‘ ë²ˆì§¸ íŒŒíŠ¸ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

    {json.dumps(analysis_data, ensure_ascii=False, indent=2)}

    3ï¸âƒ£ ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
â–¶ï¸ ì—…ë¡œë“œ ì „ëµ
 #### ìµœì ì˜ ì—…ë¡œë“œ ì‹œê°„ëŒ€:
    â€¢ ì¡°íšŒìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì‹œê°„ëŒ€
        - ì‹œê°„ëŒ€ë³„ ì¡°íšŒìˆ˜ ë¶„ì„
        - ìµœì  ì‹œê°„ëŒ€ ë„ì¶œ
        - ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ì°¨ì´
    â€¢ ì°¸ì—¬ë„ê°€ ê°€ì¥ ë†’ì€ ì‹œê°„ëŒ€
        - ëŒ“ê¸€/ì¢‹ì•„ìš” ì°¸ì—¬ìœ¨ ë¶„ì„
        - ì‹œì²­ì í™œë™ ì‹œê°„ëŒ€
        - íš¨ê³¼ì ì¸ ì—…ë¡œë“œ íƒ€ì´ë°

 #### ì‹œì²­ì ì°¸ì—¬ê°€ ë†’ì€ ê¸°ê°„:
    â€¢ ìš”ì¼ë³„ ì„±ê³¼ ë¶„ì„
        - ìš”ì¼ë³„ ì¡°íšŒìˆ˜ íŒ¨í„´
        - ì°¸ì—¬ë„ ë³€í™” ì¶”ì´
        - ìµœì  ì—…ë¡œë“œ ìš”ì¼
    â€¢ ì›”ë³„/ê³„ì ˆë³„ íŠ¸ë Œë“œ
        - ì›”ë³„ ì„±ê³¼ ë¹„êµ
        - ê³„ì ˆì  íŠ¹ì„± ë¶„ì„
        - ì¥ê¸° íŠ¸ë Œë“œ íŒ¨í„´
    â€¢ íŠ¹ì • ê¸°ê°„ ì„±ê³¼ íŒ¨í„´
        - ì£¼ìš” ì„±ê³¼ êµ¬ê°„ ë¶„ì„
        - ì„±ê³µ ìš”ì¸ ë„ì¶œ
        - ì „ëµì  í™œìš© ë°©ì•ˆ

 #### ì‹œì¦Œë³„ íŠ¸ë Œë“œ:
    â€¢ ê³„ì ˆë³„ ì„±ê³¼ ë¹„êµ
        - ê³„ì ˆë³„ ì„±ê³¼ ì°¨ì´
        - ì‹œì¦Œë³„ íŠ¹ì„± ë¶„ì„
        - ì‹œì¦Œ ë§ì¶¤ ì „ëµ
    â€¢ íŠ¹ë³„í•œ ì‹œê¸°/ì´ë²¤íŠ¸ ì˜í–¥
        - ì£¼ìš” ì´ë²¤íŠ¸ ì˜í–¥ë„
        - íŠ¹ë³„ ì‹œê¸° ì „ëµ
        - ì´ë²¤íŠ¸ í™œìš© ë°©ì•ˆ
    â€¢ ì¥ê¸°ì  íŠ¸ë Œë“œ íŒ¨í„´
        - ì—°ê°„ íŠ¸ë Œë“œ ë¶„ì„
        - ì„±ì¥ íŒ¨í„´ ë„ì¶œ
        - ì¥ê¸° ì „ëµ ìˆ˜ë¦½

4ï¸âƒ£ ì½˜í…ì¸  ì œì‘ ê°€ì´ë“œ
â–¶ï¸ í¬ë§· ìµœì í™”
 #### ì„±ê³¼ê°€ ì¢‹ì€ ì½˜í…ì¸  ìœ í˜•:
    â€¢ ìƒìœ„ ì„±ê³¼ ì½˜í…ì¸  ë¶„ì„
        - í•µì‹¬ ì„±ê³µ ìš”ì¸
        - í¬ë§·ë³„ ì„±ê³¼ ë¹„êµ
        - ìµœì í™” í¬ì¸íŠ¸
    â€¢ ê³µí†µëœ êµ¬ì„± ìš”ì†Œ
        - íš¨ê³¼ì ì¸ êµ¬ì„± ë°©ì‹
        - í•µì‹¬ êµ¬ì„± ìš”ì†Œ
        - ì‹œì²­ì ì„ í˜¸ íŒ¨í„´
    â€¢ ì°¨ë³„í™” í¬ì¸íŠ¸
        - ë…íŠ¹í•œ ê°•ì  ë¶„ì„
        - ê²½ìŸë ¥ ìš”ì†Œ
        - ì°¨ë³„í™” ì „ëµ

â–¶ï¸ ëŒ“ê¸€ ë¶„ì„ì„ í†µí•œ ê¸°íš
#### ëŒ“ê¸€ ë‚´ìš© ë¶„ì„:
    â€¢ ì£¼ìš” í‚¤ì›Œë“œ ë° í† í”½
        - ìì£¼ ì–¸ê¸‰ë˜ëŠ” í‚¤ì›Œë“œ
        - ì£¼ìš” ê´€ì‹¬ì‚¬ ë° ì£¼ì œ
    â€¢ ì‹œì²­ì ê°ì •/íƒœë„
        - ê¸ì •ì  ë°˜ì‘ íŒ¨í„´
        - ë¶€ì •ì  í”¼ë“œë°± ë¶„ì„
    â€¢ ì‹œì²­ì ë‹ˆì¦ˆ íŒŒì•…
        - ìì£¼ ë‚˜ì˜¤ëŠ” ì§ˆë¬¸
        - ìš”ì²­ì‚¬í•­ ë° ì œì•ˆ


ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ)
2. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”:
   - ì •í™•í•œ ìˆ˜ì¹˜: '47%', '2.3ë°°' ë“±
   - ì‹œê°„ ë²”ìœ„: 'ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 3ì‹œ', '15ì‹œ~19ì‹œ' ë“±
3. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ ë“¤ì—¬ì“°ê¸°ì™€ í•¨ê»˜ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
4. 'í•µì‹¬ í‚¤ì›Œë“œ'ì— ëŒ€í•´ ë¶„ì„í•  ë•ŒëŠ” ë¶„ì„í•  í‚¤ì›Œë“œëŠ” ì œì™¸í•˜ê³  ê·¸ì™¸ í‚¤ì›Œë“œë¥¼ ìœ„ì£¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ê° í•­ëª©ë³„ ë¶„ì„ ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ì™œ ì´ëŸ° ê°’ì´ ë‚˜ì™”ì„ì§€ ìš”ì¸ì— ëŒ€í•œ ê°€ì„¤ì„ ë‚´ì„¸ì›Œë³´ì„¸ìš”.

ê° í•­ëª©ì€ 20ê°œì˜ ì˜ìƒë“¤ì˜ ì˜ˆì‹œì™€ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•´ì„œ ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    def run(self):
        """ì•± ì‹¤í–‰"""
        if not self.youtube_api_key:
            st.error("YouTube API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        if st.sidebar.button("ë¶„ì„ ì‹œì‘", use_container_width=True):
            if self.keyword:
                self.run_analysis()
            else:
                st.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    app = YouTubeAnalytics()
    app.run()
